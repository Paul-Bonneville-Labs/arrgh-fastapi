{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# LLM Experimentation Notebook\n\nThis notebook is designed for **experimenting with LLM-based interactions**, specifically for entity extraction and newsletter processing.\n\n## Purpose\n\nüß™ **LLM Experimentation**: Test different prompts, models, and parameters  \nüìä **Entity Extraction Analysis**: Analyze extraction quality and tune confidence thresholds  \nüîç **Prompt Engineering**: Iterate on prompts to improve extraction accuracy  \nüìà **Performance Testing**: Test with real newsletter data and measure results  \n\n## What This Notebook Does\n\n- **Imports Production Modules**: Uses actual FastAPI EntityExtractor for testing\n- **Prompt Experimentation**: Test different prompt templates and approaches\n- **Data Analysis**: Analyze entity extraction results and quality metrics\n- **Interactive Testing**: Test with real newsletter content\n- **Performance Benchmarking**: Measure extraction speed and accuracy\n\n## What This Notebook Doesn't Do\n\n- **Infrastructure Code**: All production logic lives in `src/` directory\n- **Duplicate Implementation**: Uses FastAPI modules directly\n- **Production Deployment**: This is for experimentation only\n\n## Quick Start\n\n1. **Start FastAPI Development Server**: `./scripts/dev-server.sh`\n2. **Run This Notebook**: Experiment with LLM interactions\n3. **Apply Learnings**: Update production code in `src/processors/entity_extractor.py`\n\n---\n\n**üìö For development workflow, see: [docs/DEVELOPMENT-WORKFLOW.md](../docs/DEVELOPMENT-WORKFLOW.md)**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Setup and Configuration\n\n**Import production modules and setup experimentation environment**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup: Import Production Modules\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import List, Dict, Any\nfrom datetime import datetime\nimport json\nimport time\n\n# Add src directory to path for imports\ncurrent_dir = Path.cwd()\nproject_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\nsrc_path = project_root / 'src'\nsys.path.insert(0, str(src_path))\n\n# Load environment variables\nfrom dotenv import load_dotenv\nload_dotenv(project_root / \".env.local\")\n\nprint(\"üî¨ LLM Experimentation Environment\")\nprint(\"=\" * 50)\n\n# Import production modules\ntry:\n    from config import get_settings\n    from models.newsletter import Entity, Newsletter\n    from processors.entity_extractor import EntityExtractor\n    \n    # Get production configuration\n    config = get_settings()\n    \n    # Initialize entity extractor with production settings\n    entity_extractor = EntityExtractor(config)\n    \n    print(\"‚úÖ Production modules imported successfully\")\n    print(f\"‚úÖ EntityExtractor initialized with model: {config.LLM_MODEL}\")\n    print(f\"‚úÖ Confidence threshold: {config.ENTITY_CONFIDENCE_THRESHOLD}\")\n    print(f\"‚úÖ Max entities per newsletter: {config.MAX_ENTITIES_PER_NEWSLETTER}\")\n    \nexcept ImportError as e:\n    print(f\"‚ùå Failed to import production modules: {e}\")\n    print(\"   Make sure FastAPI development environment is set up\")\n    print(\"   Run: ./scripts/dev-setup.sh\")\n    entity_extractor = None\n\nprint(\"\\nüß™ Ready for LLM experimentation!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Test Data for Experimentation\n\n**Sample newsletter content for testing different scenarios**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test Data: Sample Newsletter Content\n\n# Collection of test content for experimenting with entity extraction\ntest_newsletters = {\n    \"ai_news\": \"\"\"\n    OpenAI announced GPT-5 at their developer conference in San Francisco. \n    CEO Sam Altman presented the new capabilities during the OpenAI DevDay 2024 event.\n    Microsoft expanded their Azure AI services with enterprise features.\n    Google launched Gemini Pro focusing on AI Safety.\n    \"\"\",\n    \n    \"tech_startup\": \"\"\"\n    Y Combinator's latest batch includes 20 AI startups from Silicon Valley.\n    Anthropic raised $100M Series B led by Spark Capital.\n    Meta's Reality Labs division showcased new VR headsets at CES 2024.\n    TechCrunch reported that Apple is developing autonomous vehicles.\n    \"\"\",\n    \n    \"research_heavy\": \"\"\"\n    Stanford University published research on large language models in Nature.\n    Professor Fei-Fei Li's computer vision lab achieved breakthrough results.\n    MIT and Harvard collaborated on quantum computing applications.\n    The Allen Institute for AI released new datasets for machine learning.\n    \"\"\",\n    \n    \"business_news\": \"\"\"\n    Amazon Web Services launched new cloud infrastructure in Tokyo.\n    Salesforce acquired data analytics startup MuleSoft for $6.5 billion.\n    Tesla reported record quarterly earnings driven by Model 3 sales.\n    Netflix expanded into gaming with mobile app development.\n    \"\"\",\n    \n    \"short_snippet\": \"\"\"\n    OpenAI released ChatGPT-4 with improved reasoning capabilities.\n    \"\"\",\n    \n    \"complex_entities\": \"\"\"\n    The World Economic Forum in Davos featured discussions on AI governance.\n    European Union's AI Act was implemented across member states.\n    NATO established a new cyber defense initiative in Brussels.\n    United Nations Climate Change Conference addressed green technology.\n    \"\"\"\n}\n\nprint(\"üì∞ Test newsletter content loaded:\")\nfor name, content in test_newsletters.items():\n    word_count = len(content.split())\n    print(f\"  ‚Ä¢ {name}: {word_count} words\")\n\nprint(f\"\\nüìä Total test cases: {len(test_newsletters)}\")\nprint(\"üß™ Ready to experiment with different content types!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Entity Extraction Testing\n\n**Test the production entity extractor with different content**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Entity Extraction: Test Production System\n\ndef test_entity_extraction(content_name: str, content: str, show_details: bool = True):\n    \"\"\"Test entity extraction with production system.\"\"\"\n    if not entity_extractor:\n        print(\"‚ùå Entity extractor not available\")\n        return None\n    \n    print(f\"üîç Testing: {content_name}\")\n    print(f\"üìù Content: {content[:100]}{'...' if len(content) > 100 else ''}\")\n    \n    # Time the extraction\n    start_time = time.time()\n    entities = entity_extractor.extract_entities(content)\n    extraction_time = time.time() - start_time\n    \n    print(f\"‚è±Ô∏è  Extraction time: {extraction_time:.2f}s\")\n    print(f\"üìä Entities found: {len(entities)}\")\n    \n    if entities and show_details:\n        print(\"\\nüìã Entity Details:\")\n        entity_counts = {}\n        for i, entity in enumerate(entities):\n            entity_type = entity.type\n            entity_counts[entity_type] = entity_counts.get(entity_type, 0) + 1\n            \n            print(f\"  {i+1:2d}. {entity.name:25} | {entity.type:12} | {entity.confidence:.2f}\")\n            if entity.context:\n                print(f\"      Context: {entity.context[:80]}{'...' if len(entity.context) > 80 else ''}\")\n        \n        print(f\"\\nüìà Entity Type Summary:\")\n        for entity_type, count in sorted(entity_counts.items()):\n            print(f\"  {entity_type}: {count}\")\n    \n    print(\"=\" * 60)\n    return {\n        'content_name': content_name,\n        'entities': entities,\n        'extraction_time': extraction_time,\n        'entity_count': len(entities)\n    }\n\n# Test all newsletter content\nprint(\"üß™ Testing Entity Extraction with All Content Types\")\nprint(\"=\" * 60)\n\nresults = {}\nfor name, content in test_newsletters.items():\n    result = test_entity_extraction(name, content)\n    if result:\n        results[name] = result\n    print()\n\n# Summary analysis\nif results:\n    print(\"üìä EXTRACTION SUMMARY\")\n    print(\"=\" * 60)\n    total_entities = sum(r['entity_count'] for r in results.values())\n    avg_time = sum(r['extraction_time'] for r in results.values()) / len(results)\n    \n    print(f\"Total test cases: {len(results)}\")\n    print(f\"Total entities extracted: {total_entities}\")\n    print(f\"Average extraction time: {avg_time:.2f}s\")\n    \n    print(f\"\\nPer-test breakdown:\")\n    for name, result in results.items():\n        print(f\"  {name:15}: {result['entity_count']:2d} entities in {result['extraction_time']:.2f}s\")\n    \n    print(\"\\nüéØ Use these results to tune prompts and thresholds!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Prompt Experimentation\n\n**Experiment with different prompts and analyze results**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prompt Experimentation: Test Different Approaches\n\ndef test_custom_prompt(content: str, custom_prompt: str, test_name: str):\n    \"\"\"Test entity extraction with a custom prompt.\"\"\"\n    if not entity_extractor:\n        print(\"‚ùå Entity extractor not available\")\n        return None\n    \n    print(f\"üß™ Testing Custom Prompt: {test_name}\")\n    print(f\"üìù Prompt (first 200 chars): {custom_prompt[:200]}...\")\n    \n    # Temporarily modify the extractor's prompt\n    original_prompt = entity_extractor.ENTITY_EXTRACTION_PROMPT\n    entity_extractor.ENTITY_EXTRACTION_PROMPT = custom_prompt\n    \n    try:\n        start_time = time.time()\n        entities = entity_extractor.extract_entities(content)\n        extraction_time = time.time() - start_time\n        \n        print(f\"‚è±Ô∏è  Extraction time: {extraction_time:.2f}s\")\n        print(f\"üìä Entities found: {len(entities)}\")\n        \n        if entities:\n            entity_counts = {}\n            for entity in entities:\n                entity_type = entity.type\n                entity_counts[entity_type] = entity_counts.get(entity_type, 0) + 1\n            \n            print(f\"üìà Entity breakdown: {dict(entity_counts)}\")\n            \n            # Show top entities\n            top_entities = sorted(entities, key=lambda e: e.confidence, reverse=True)[:5]\n            print(f\"üéØ Top entities:\")\n            for i, entity in enumerate(top_entities):\n                print(f\"  {i+1}. {entity.name} ({entity.type}) - {entity.confidence:.2f}\")\n        \n        print(\"=\" * 60)\n        return entities\n        \n    finally:\n        # Restore original prompt\n        entity_extractor.ENTITY_EXTRACTION_PROMPT = original_prompt\n\n# Experimental prompts\nexperimental_prompts = {\n    \"concise\": \"\"\"\nExtract key entities from this newsletter content. Focus on:\n- Organizations (companies, institutions)\n- People (individuals mentioned)  \n- Products (software, hardware, services)\n- Events (conferences, launches)\n- Locations (cities, countries)\n- Topics (subject areas, technologies)\n\nContent: {content}\n\nReturn JSON format:\n{{\"entities\": [{{\"name\": \"EntityName\", \"type\": \"Organization|Person|Product|Event|Location|Topic\", \"confidence\": 0.9}}]}}\n\"\"\",\n\n    \"detailed_analysis\": \"\"\"\nYou are an expert information extraction specialist. Analyze this newsletter content and extract entities with high precision.\n\nENTITY CATEGORIES:\nüè¢ Organization: Companies, startups, institutions, government bodies\nüë§ Person: Individuals, executives, researchers, public figures  \nüõ†Ô∏è Product: Software, hardware, services, models, platforms\nüé™ Event: Conferences, launches, announcements, meetings\nüåç Location: Cities, countries, regions, specific venues\nüß† Topic: Technologies, fields of study, research areas\n\nEXTRACTION GUIDELINES:\n- Only extract entities you are highly confident about (>0.8)\n- Provide context showing where each entity was mentioned\n- Include aliases or alternative names if present\n- Rate confidence from 0.0 to 1.0 based on clarity and context\n\nNEWSLETTER CONTENT:\n{content}\n\nREQUIRED OUTPUT (JSON only):\n{{\"entities\": [{{\"name\": \"EntityName\", \"type\": \"Category\", \"aliases\": [\"Alt1\"], \"confidence\": 0.95, \"context\": \"sentence mentioning entity\"}}]}}\n\"\"\",\n\n    \"strict_validation\": \"\"\"\nExtract entities from newsletter content with strict validation.\n\nSTRICT CRITERIA:\n- Only well-known, clearly identifiable entities\n- Minimum confidence: 0.9\n- Clear context required for each entity\n- No ambiguous or unclear references\n\nEntity types: Organization, Person, Product, Event, Location, Topic\n\nContent: {content}\n\nJSON output only: {{\"entities\": [...]}}\n\"\"\"\n}\n\n# Test different prompts with AI news content\ntest_content = test_newsletters[\"ai_news\"]\n\nprint(\"üî¨ PROMPT EXPERIMENTATION\")\nprint(\"=\" * 60)\n\nprompt_results = {}\nfor prompt_name, prompt_template in experimental_prompts.items():\n    entities = test_custom_prompt(test_content, prompt_template, prompt_name)\n    if entities:\n        prompt_results[prompt_name] = entities\n    print()\n\n# Compare results\nif prompt_results:\n    print(\"üìä PROMPT COMPARISON RESULTS\")\n    print(\"=\" * 60)\n    \n    for prompt_name, entities in prompt_results.items():\n        avg_confidence = sum(e.confidence for e in entities) / len(entities) if entities else 0\n        entity_types = set(e.type for e in entities)\n        \n        print(f\"{prompt_name:20}: {len(entities):2d} entities, avg confidence: {avg_confidence:.2f}\")\n        print(f\"{'':20}  Types: {', '.join(sorted(entity_types))}\")\n    \n    print(\"\\nüéØ Use this analysis to improve the production prompt!\")\n    print(\"üí° Update src/processors/entity_extractor.py with best performing prompt\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: Neo4j Client - Import from FastAPI\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\n\nprint(\"üìä Importing Neo4j client from FastAPI...\")\n\ntry:\n    # Import the actual Neo4j client from FastAPI\n    from graph.neo4j_client import Neo4jClient as FastAPINeo4jClient\n    \n    print(\"‚úÖ Successfully imported Neo4jClient from FastAPI\")\n    \n    # Initialize with configuration\n    neo4j_client = FastAPINeo4jClient(config)\n    \n    print(\"‚úÖ Neo4j client initialized with production configuration\")\n    \n    # Test connection\n    if neo4j_client.connect():\n        # Display current graph statistics\n        stats = neo4j_client.get_graph_stats()\n        print(\"\\nüìä Current graph statistics:\")\n        for key, value in stats.items():\n            print(f\"  {key.capitalize()}: {value}\")\n        \n        # Test basic query\n        test_result = neo4j_client.execute_query(\"RETURN 'Neo4j is working!' as message\")\n        if test_result:\n            print(f\"‚úÖ Test query result: {test_result[0]['message']}\")\n    else:\n        print(\"‚ö†Ô∏è Neo4j operations will be limited without connection\")\n    \n    print(\"\\nüéØ Now using production Neo4j client directly!\")\n    \nexcept ImportError as e:\n    print(f\"‚ùå Failed to import FastAPI Neo4j client: {e}\")\n    print(\"  This is expected during the transition phase.\")\n    print(\"  The production Neo4j client is now the single source of truth.\")\n    print(\"  For development, use the FastAPI codebase directly with hot reload.\")\n    \n    # Simple fallback Neo4j client\n    class Neo4jClient:\n        \"\"\"Fallback Neo4j client.\"\"\"\n        \n        def __init__(self, config=None):\n            self.connected = False\n            print(\"‚ö†Ô∏è Using fallback Neo4j client (limited functionality)\")\n        \n        def connect(self) -> bool:\n            print(\"‚ö†Ô∏è Fallback Neo4j client - no real connection\")\n            return False\n        \n        def execute_query(self, query: str, parameters: Dict[str, Any] = None) -> List[Dict]:\n            print(\"‚ö†Ô∏è Fallback Neo4j client - no real query execution\")\n            return []\n        \n        def get_graph_stats(self) -> Dict[str, int]:\n            return {\"message\": \"Use FastAPI development environment for Neo4j operations\"}\n    \n    neo4j_client = Neo4jClient(config)\n\nprint(\"\\n‚úÖ Neo4j client setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newsletter Processor (Complete Workflow)\n",
    "\n",
    "**FastAPI File**: `/Users/paulbonneville/Developer/arrgh-fastapi/src/workflows/newsletter_processor.py`\n",
    "\n",
    "**Purpose**: Complete newsletter processing pipeline orchestrating all components for end-to-end workflow.\n",
    "\n",
    "**What this mirrors**: The complete workflow orchestration from the FastAPI app, including:\n",
    "- `NewsletterProcessor` class - Main orchestrator for the complete processing pipeline\n",
    "- `process_newsletter()` - 5-step workflow: HTML cleaning ‚Üí entity extraction ‚Üí Neo4j storage ‚Üí summary generation\n",
    "- `_generate_text_summary()` - Intelligent summary creation with entity breakdown and metrics\n",
    "- Component integration: HTMLProcessor, EntityExtractor, Neo4jClient coordination\n",
    "- Neo4j graph operations: entity creation/updates, relationship linking, newsletter node management\n",
    "- Performance metrics and processing time tracking\n",
    "- Comprehensive error handling with rollback capabilities\n",
    "- Response generation with detailed processing statistics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Newsletter Processor - Import from FastAPI\nimport uuid\nfrom datetime import datetime\nfrom typing import Dict, List, Any\n\nprint(\"üîÑ Importing Newsletter Processor from FastAPI...\")\n\ntry:\n    # Import the actual NewsletterProcessor from FastAPI\n    from workflows.newsletter_processor import NewsletterProcessor as FastAPINewsletterProcessor\n    \n    print(\"‚úÖ Successfully imported NewsletterProcessor from FastAPI\")\n    \n    # Initialize with configuration\n    newsletter_processor = FastAPINewsletterProcessor(config)\n    \n    print(\"‚úÖ Newsletter processor initialized with production configuration\")\n    print(\"üîÑ Complete pipeline: HTML ‚Üí Entities ‚Üí Neo4j ‚Üí Summary\")\n    print(\"üìä Functions: process_newsletter()\")\n    \n    print(\"\\nüéØ Now using production NewsletterProcessor directly!\")\n    \nexcept ImportError as e:\n    print(f\"‚ùå Failed to import FastAPI NewsletterProcessor: {e}\")\n    print(\"  This is expected during the transition phase.\")\n    print(\"  The production NewsletterProcessor is now the single source of truth.\")\n    print(\"  For development, use the FastAPI codebase directly with hot reload.\")\n    \n    # Simple fallback processor that encourages using FastAPI directly\n    class NewsletterProcessor:\n        \"\"\"Fallback newsletter processor.\"\"\"\n        \n        def __init__(self, config_obj):\n            self.config = config_obj\n            print(\"‚ö†Ô∏è Using fallback Newsletter processor (limited functionality)\")\n            print(\"  For full functionality, use the FastAPI development environment\")\n        \n        def process_newsletter(self, newsletter: Newsletter) -> NewsletterProcessingResponse:\n            \"\"\"Fallback process that returns minimal response.\"\"\"\n            print(\"‚ö†Ô∏è Fallback processor - use FastAPI development environment for real processing\")\n            \n            return NewsletterProcessingResponse(\n                status=\"fallback\",\n                newsletter_id=newsletter.newsletter_id or str(uuid.uuid4()),\n                processing_time=0.0,\n                entities_extracted=0,\n                entities_new=0,\n                entities_updated=0,\n                entity_summary={},\n                text_summary=\"Use FastAPI development environment for actual newsletter processing\",\n                errors=[\"Using fallback processor - switch to FastAPI development\"]\n            )\n    \n    newsletter_processor = NewsletterProcessor(config)\n\nprint(\"\\n‚úÖ Newsletter Processor setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing & Validation (Complete Pipeline Test)\n",
    "\n",
    "**FastAPI File**: Testing framework (not directly mirrored - notebook-specific utilities)\n",
    "\n",
    "**Purpose**: Complete pipeline testing and validation with comprehensive test scenarios and performance assessment.\n",
    "\n",
    "**What this mirrors**: Testing utilities that validate the complete FastAPI workflow, including:\n",
    "- `run_complete_pipeline_test()` - Full end-to-end pipeline test with realistic AI newsletter content\n",
    "- `validate_pipeline_results()` - Performance and quality assessment with multiple metrics\n",
    "- `quick_test()` - Minimal test for rapid debugging and component validation\n",
    "- Sample data generation with rich entity content (companies, people, products, events, locations)\n",
    "- Performance benchmarking: processing time, entity extraction quality, success rates\n",
    "- Error handling validation and pipeline robustness testing\n",
    "- Neo4j integration testing with graph database operations\n",
    "- Comprehensive reporting with success/failure analysis and recommendations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Running complete pipeline test...\n",
      "üöÄ Starting complete pipeline test...\n",
      "  Newsletter: AI Weekly Newsletter #245 - Development Test\n",
      "  Newsletter ID: ai-weekly-245-test-1752119831\n",
      "üöÄ Starting newsletter processing: AI Weekly Newsletter #245 - Development Test\n",
      "1Ô∏è‚É£ Processing HTML content...\n",
      "\u001b[2m2025-07-09 21:57:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTML content cleaned          \u001b[0m \u001b[36mcleaned_length\u001b[0m=\u001b[35m1058\u001b[0m \u001b[36moriginal_length\u001b[0m=\u001b[35m1909\u001b[0m\n",
      "\u001b[2m2025-07-09 21:57:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mText sections extracted       \u001b[0m \u001b[36mheaders_count\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mlinks_count\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mlists_count\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mparagraphs_count\u001b[0m=\u001b[35m8\u001b[0m\n",
      "   ‚úÖ Cleaned text: 1058 characters\n",
      "2Ô∏è‚É£ Extracting entities...\n",
      "   ‚úÖ Extracted 19 entities\n",
      "3Ô∏è‚É£ Creating newsletter node...\n",
      "   ‚úÖ Newsletter node created\n",
      "4Ô∏è‚É£ Processing entities in graph...\n",
      "   ‚úÖ Processed: 0 new, 19 updated, 19 linked\n",
      "5Ô∏è‚É£ Generating summary...\n",
      "   ‚úÖ Processing completed in 20.53 seconds\n",
      "\n",
      "‚úÖ Pipeline completed: success\n",
      "  - Processing time: 20.53s\n",
      "  - Entities extracted: 19\n",
      "  - New entities: 0\n",
      "  - Updated entities: 19\n",
      "  - Entity summary: {'Organization': 6, 'Product': 3, 'Person': 3, 'Event': 3, 'Location': 2, 'Topic': 2}\n",
      "  - Text summary: Newsletter processed with 19 entities extracted. Entity breakdown: 6 Organization, 3 Product, 3 Person, 3 Event, 2 Location, 2 Topic. Content structure: 6 headers, 8 paragraphs. Top entities: OpenAI, Microsoft, Google, Stanford University, MIT.\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìã Pipeline Validation Results:\n",
      "  Status: success\n",
      "  Processing time: 20.53 seconds\n",
      "  Entities extracted: 19\n",
      "  Entities new: 0\n",
      "  Entities updated: 19\n",
      "  ‚úÖ Performance: Good (< 30s)\n",
      "  üéØ Entity extraction: Excellent (> 15 entities)\n",
      "\n",
      "üéâ All tests passed! Pipeline is working correctly.\n",
      "\n",
      "‚úÖ Pipeline testing complete!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "import time\n",
    "\n",
    "def run_complete_pipeline_test():\n",
    "    \"\"\"Test the complete newsletter processing pipeline.\"\"\"\n",
    "    \n",
    "    # Sample newsletter for testing\n",
    "    sample_html = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head><title>AI Weekly Newsletter #245</title></head>\n",
    "    <body>\n",
    "        <h1>AI Weekly Newsletter #245</h1>\n",
    "        <p>Welcome to this week's AI updates!</p>\n",
    "        \n",
    "        <h2>Major Announcements</h2>\n",
    "        <p><strong>OpenAI</strong> announced the release of <strong>GPT-5</strong> at their \n",
    "        developer conference in <strong>San Francisco</strong>. CEO <strong>Sam Altman</strong> \n",
    "        presented the new capabilities during the <strong>OpenAI DevDay 2024</strong> event.</p>\n",
    "        \n",
    "        <h2>Company Updates</h2>\n",
    "        <p><strong>Microsoft</strong> expanded their <strong>Azure AI</strong> services with \n",
    "        new enterprise features. The announcement was made by <strong>Satya Nadella</strong> \n",
    "        during the <strong>Microsoft Build 2024</strong> conference.</p>\n",
    "        \n",
    "        <h2>Industry News</h2>\n",
    "        <p><strong>Google</strong> launched their new <strong>Gemini Pro</strong> model, \n",
    "        focusing on <strong>AI Safety</strong> and <strong>Responsible AI</strong> development. \n",
    "        The launch event was held at <strong>Google I/O 2024</strong> in <strong>Mountain View</strong>.</p>\n",
    "        \n",
    "        <h2>Educational Content</h2>\n",
    "        <p><strong>Stanford University</strong> announced a new <strong>AI Safety</strong> course \n",
    "        taught by renowned professor <strong>Fei-Fei Li</strong>. The course will cover \n",
    "        <strong>Machine Learning</strong> ethics and <strong>AI Alignment</strong>.</p>\n",
    "        \n",
    "        <h2>Research Highlights</h2>\n",
    "        <p>New research on <strong>Quantum Computing</strong> applications in <strong>AI</strong> \n",
    "        was published by researchers at <strong>MIT</strong> and <strong>IBM Research</strong>. \n",
    "        The paper explores <strong>Quantum Machine Learning</strong> algorithms.</p>\n",
    "        \n",
    "        <p>Thanks for reading! See you next week.</p>\n",
    "        <p>Best regards,<br>The AI Weekly Team</p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create newsletter object\n",
    "    newsletter = Newsletter(\n",
    "        html_content=sample_html,\n",
    "        subject=\"AI Weekly Newsletter #245 - Development Test\",\n",
    "        sender=\"ai-weekly@example.com\",\n",
    "        received_date=datetime.now(timezone.utc),\n",
    "        newsletter_id=f\"ai-weekly-245-test-{int(time.time())}\"\n",
    "    )\n",
    "    \n",
    "    print(\"üöÄ Starting complete pipeline test...\")\n",
    "    print(f\"  Newsletter: {newsletter.subject}\")\n",
    "    print(f\"  Newsletter ID: {newsletter.newsletter_id}\")\n",
    "    \n",
    "    # Use the newsletter processor\n",
    "    try:\n",
    "        response = newsletter_processor.process_newsletter(newsletter)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Pipeline completed: {response.status}\")\n",
    "        print(f\"  - Processing time: {response.processing_time:.2f}s\")\n",
    "        print(f\"  - Entities extracted: {response.entities_extracted}\")\n",
    "        print(f\"  - New entities: {response.entities_new}\")\n",
    "        print(f\"  - Updated entities: {response.entities_updated}\")\n",
    "        print(f\"  - Entity summary: {response.entity_summary}\")\n",
    "        print(f\"  - Text summary: {response.text_summary}\")\n",
    "        \n",
    "        if response.errors:\n",
    "            print(f\"  - Errors: {response.errors}\")\n",
    "            \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Pipeline test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def validate_pipeline_results(response) -> bool:\n",
    "    \"\"\"Validate pipeline results and provide feedback.\"\"\"\n",
    "    if not response:\n",
    "        print(\"‚ùå No response to validate\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\nüìã Pipeline Validation Results:\")\n",
    "    print(f\"  Status: {response.status}\")\n",
    "    print(f\"  Processing time: {response.processing_time:.2f} seconds\")\n",
    "    print(f\"  Entities extracted: {response.entities_extracted}\")\n",
    "    \n",
    "    if neo4j_client.connected:\n",
    "        print(f\"  Entities new: {response.entities_new}\")\n",
    "        print(f\"  Entities updated: {response.entities_updated}\")\n",
    "    \n",
    "    if response.errors:\n",
    "        print(f\"  ‚ùå Errors ({len(response.errors)}):\")\n",
    "        for error in response.errors:\n",
    "            print(f\"    - {error}\")\n",
    "    \n",
    "    # Performance assessment\n",
    "    if response.processing_time < 10:\n",
    "        print(\"  ‚ö° Performance: Excellent (< 10s)\")\n",
    "    elif response.processing_time < 30:\n",
    "        print(\"  ‚úÖ Performance: Good (< 30s)\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è Performance: Slow (> 30s)\")\n",
    "    \n",
    "    # Entity extraction assessment\n",
    "    if response.entities_extracted > 15:\n",
    "        print(\"  üéØ Entity extraction: Excellent (> 15 entities)\")\n",
    "    elif response.entities_extracted > 5:\n",
    "        print(\"  ‚úÖ Entity extraction: Good (> 5 entities)\")\n",
    "    elif response.entities_extracted > 0:\n",
    "        print(\"  ‚ö†Ô∏è Entity extraction: Limited (1-5 entities)\")\n",
    "    else:\n",
    "        print(\"  ‚ùå Entity extraction: Failed (0 entities)\")\n",
    "    \n",
    "    return response.status == 'success' and len(response.errors) == 0\n",
    "\n",
    "def quick_test():\n",
    "    \"\"\"Quick test with minimal content.\"\"\"\n",
    "    test_html = \"<html><body><h1>Test</h1><p>OpenAI released GPT-4 in San Francisco.</p></body></html>\"\n",
    "    newsletter = Newsletter(\n",
    "        html_content=test_html,\n",
    "        subject=\"Quick Test\",\n",
    "        sender=\"test@example.com\",\n",
    "        newsletter_id=f\"quick-test-{int(time.time())}\"\n",
    "    )\n",
    "    \n",
    "    print(\"üî¨ Running quick test...\")\n",
    "    response = newsletter_processor.process_newsletter(newsletter)\n",
    "    print(f\"Quick test result: {response.status}, {response.entities_extracted} entities\")\n",
    "    return response\n",
    "\n",
    "# Run the complete pipeline test\n",
    "print(\"üî¨ Running complete pipeline test...\")\n",
    "test_response = run_complete_pipeline_test()\n",
    "\n",
    "# Validate results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "validation_passed = validate_pipeline_results(test_response)\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"\\nüéâ All tests passed! Pipeline is working correctly.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some tests failed. Check the results above.\")\n",
    "    print(\"\\nüí° Running quick test to diagnose...\")\n",
    "    quick_response = quick_test()\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Export Helper (Sync changes back to FastAPI)\n",
    "\n",
    "**FastAPI File**: Development utilities (not directly mirrored - notebook-specific development tools)\n",
    "\n",
    "**Purpose**: Synchronization tools for maintaining code consistency between notebook development and FastAPI production files.\n",
    "\n",
    "**What this mirrors**: Development workflow utilities that facilitate notebook-to-FastAPI synchronization, including:\n",
    "- `compare_files()` - File difference analysis between notebook code and FastAPI files\n",
    "- `export_to_fastapi()` - Safe code export with automatic backup creation\n",
    "- `sync_status_check()` - Comprehensive status check for all components across notebook and FastAPI\n",
    "- `validate_fastapi_imports()` - Import validation to ensure exported code works in FastAPI context\n",
    "- `development_summary()` - Environment status dashboard with configuration and test results\n",
    "- `quick_development_check()` - Complete development environment validation workflow\n",
    "- File mapping system for all FastAPI components (config, models, processors, workflows)\n",
    "- Development lifecycle management with backup and rollback capabilities\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Code Export Helper loaded successfully\n",
      "üîÑ Functions: compare_files(), export_to_fastapi(), sync_status_check()\n",
      "üìÅ File mappings configured for all components\n",
      "\n",
      "üí° Usage:\n",
      "  - sync_status_check(): Check sync status of all components\n",
      "  - quick_development_check(): Run development status check\n",
      "  - validate_fastapi_imports(): Test FastAPI imports\n",
      "  - development_summary(): Show current environment status\n",
      "üöÄ Quick Development Status Check\n",
      "\n",
      "1. Checking sync status...\n",
      "üîÑ Checking sync status with FastAPI...\n",
      "\n",
      "üì¶ Checking html_processor...\n",
      "  ‚úÖ File exists\n",
      "\n",
      "üì¶ Checking entity_extractor...\n",
      "  ‚úÖ File exists\n",
      "\n",
      "üì¶ Checking neo4j_client...\n",
      "  ‚úÖ File exists\n",
      "\n",
      "üì¶ Checking newsletter_processor...\n",
      "  ‚úÖ File exists\n",
      "\n",
      "üìä Sync Status Summary:\n",
      "  - html_processor: ‚úÖ File exists\n",
      "  - entity_extractor: ‚úÖ File exists\n",
      "  - neo4j_client: ‚úÖ File exists\n",
      "  - newsletter_processor: ‚úÖ File exists\n",
      "\n",
      "2. Validating components...\n",
      "üîç Validating FastAPI imports...\n",
      "‚úÖ config.py imports successfully\n",
      "‚úÖ models/newsletter.py imports successfully\n",
      "‚úÖ processors/html_processor.py imports successfully\n",
      "‚ö†Ô∏è entity_extractor import issue: attempted relative import beyond top-level package\n",
      "\n",
      "3. Development summary...\n",
      "üìã Development Environment Summary\n",
      "========================================\n",
      "‚úÖ OpenAI configured: True\n",
      "‚úÖ Neo4j connected: True\n",
      "‚úÖ HTML Processor ready: True\n",
      "‚úÖ Entity Extractor ready: True\n",
      "‚úÖ Newsletter Processor ready: True\n",
      "\n",
      "üìä Last Test Results:\n",
      "  Status: success\n",
      "  Entities: 19\n",
      "  Time: 20.53s\n",
      "\n",
      "üéØ Ready for development and testing!\n",
      "\n",
      "üéâ Development check completed!\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Define file mappings\n",
    "FILE_MAPPINGS = {\n",
    "    'config': '/Users/paulbonneville/Developer/arrgh-fastapi/src/config.py',\n",
    "    'models': '/Users/paulbonneville/Developer/arrgh-fastapi/src/models/newsletter.py',\n",
    "    'html_processor': '/Users/paulbonneville/Developer/arrgh-fastapi/src/processors/html_processor.py',\n",
    "    'entity_extractor': '/Users/paulbonneville/Developer/arrgh-fastapi/src/processors/entity_extractor.py',\n",
    "    'neo4j_client': '/Users/paulbonneville/Developer/arrgh-fastapi/src/graph/neo4j_client.py',\n",
    "    'newsletter_processor': '/Users/paulbonneville/Developer/arrgh-fastapi/src/workflows/newsletter_processor.py'\n",
    "}\n",
    "\n",
    "def compare_files(notebook_code: str, fastapi_file: str) -> bool:\n",
    "    \"\"\"Compare notebook code with FastAPI file.\"\"\"\n",
    "    try:\n",
    "        with open(fastapi_file, 'r') as f:\n",
    "            fastapi_code = f.read()\n",
    "        \n",
    "        # Simple comparison - in production, you'd want more sophisticated matching\n",
    "        notebook_lines = notebook_code.strip().split('\\n')\n",
    "        fastapi_lines = fastapi_code.strip().split('\\n')\n",
    "        \n",
    "        # Show diff if different\n",
    "        if notebook_lines != fastapi_lines:\n",
    "            print(f\"üìä Differences found in {Path(fastapi_file).name}:\")\n",
    "            diff = difflib.unified_diff(\n",
    "                fastapi_lines, notebook_lines,\n",
    "                fromfile='FastAPI', tofile='Notebook',\n",
    "                lineterm='', n=3\n",
    "            )\n",
    "            for line in list(diff)[:20]:  # Show first 20 lines of diff\n",
    "                print(line)\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"‚úÖ {Path(fastapi_file).name} matches notebook code\")\n",
    "            return True\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå FastAPI file not found: {fastapi_file}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error comparing files: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def export_to_fastapi(component: str, notebook_code: str, backup: bool = True) -> bool:\n",
    "    \"\"\"Export notebook code to FastAPI file.\"\"\"\n",
    "    if component not in FILE_MAPPINGS:\n",
    "        print(f\"‚ùå Unknown component: {component}\")\n",
    "        return False\n",
    "    \n",
    "    fastapi_file = FILE_MAPPINGS[component]\n",
    "    \n",
    "    try:\n",
    "        # Create backup if requested\n",
    "        if backup and Path(fastapi_file).exists():\n",
    "            backup_file = f\"{fastapi_file}.backup\"\n",
    "            shutil.copy2(fastapi_file, backup_file)\n",
    "            print(f\"üìã Backup created: {backup_file}\")\n",
    "        \n",
    "        # Write notebook code to FastAPI file\n",
    "        with open(fastapi_file, 'w') as f:\n",
    "            f.write(notebook_code)\n",
    "        \n",
    "        print(f\"‚úÖ Exported to {Path(fastapi_file).name}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Export failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def sync_status_check():\n",
    "    \"\"\"Check sync status of all components.\"\"\"\n",
    "    print(\"üîÑ Checking sync status with FastAPI...\\n\")\n",
    "    \n",
    "    sync_status = {}\n",
    "    \n",
    "    # Note: In a real implementation, you'd extract the actual code from notebook cells\n",
    "    # This is a placeholder showing the concept\n",
    "    \n",
    "    components = ['html_processor', 'entity_extractor', 'neo4j_client', 'newsletter_processor']\n",
    "    \n",
    "    for component in components:\n",
    "        print(f\"üì¶ Checking {component}...\")\n",
    "        \n",
    "        # This would compare actual notebook cell code with FastAPI files\n",
    "        # For now, we'll just check if files exist\n",
    "        fastapi_file = FILE_MAPPINGS[component]\n",
    "        if Path(fastapi_file).exists():\n",
    "            sync_status[component] = \"‚úÖ File exists\"\n",
    "        else:\n",
    "            sync_status[component] = \"‚ùå File missing\"\n",
    "        \n",
    "        print(f\"  {sync_status[component]}\")\n",
    "        print()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"üìä Sync Status Summary:\")\n",
    "    for component, status in sync_status.items():\n",
    "        print(f\"  - {component}: {status}\")\n",
    "    \n",
    "    return sync_status\n",
    "\n",
    "def validate_fastapi_imports():\n",
    "    \"\"\"Validate that FastAPI can import our changes.\"\"\"\n",
    "    print(\"üîç Validating FastAPI imports...\")\n",
    "    \n",
    "    try:\n",
    "        # Test basic imports\n",
    "        import config\n",
    "        print(\"‚úÖ config.py imports successfully\")\n",
    "        \n",
    "        from models import newsletter\n",
    "        print(\"‚úÖ models/newsletter.py imports successfully\")\n",
    "        \n",
    "        # Test processor imports\n",
    "        try:\n",
    "            from processors import html_processor\n",
    "            print(\"‚úÖ processors/html_processor.py imports successfully\")\n",
    "        except ImportError as e:\n",
    "            print(f\"‚ö†Ô∏è html_processor import issue: {e}\")\n",
    "        \n",
    "        try:\n",
    "            from processors import entity_extractor\n",
    "            print(\"‚úÖ processors/entity_extractor.py imports successfully\")\n",
    "        except ImportError as e:\n",
    "            print(f\"‚ö†Ô∏è entity_extractor import issue: {e}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Import validation failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def development_summary():\n",
    "    \"\"\"Provide a summary of the development environment.\"\"\"\n",
    "    print(\"üìã Development Environment Summary\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Configuration status\n",
    "    print(f\"‚úÖ OpenAI configured: {bool(config.openai_api_key and not config.openai_api_key.startswith('sk-your-'))}\")\n",
    "    print(f\"‚úÖ Neo4j connected: {neo4j_client.connected if 'neo4j_client' in globals() else False}\")\n",
    "    print(f\"‚úÖ HTML Processor ready: {'html_processor' in globals()}\")\n",
    "    print(f\"‚úÖ Entity Extractor ready: {'openai_client' in globals() and openai_client is not None}\")\n",
    "    print(f\"‚úÖ Newsletter Processor ready: {'newsletter_processor' in globals()}\")\n",
    "    \n",
    "    # Recent test results\n",
    "    if 'test_response' in globals() and test_response:\n",
    "        print(f\"\\nüìä Last Test Results:\")\n",
    "        print(f\"  Status: {test_response.status}\")\n",
    "        print(f\"  Entities: {test_response.entities_extracted}\")\n",
    "        print(f\"  Time: {test_response.processing_time:.2f}s\")\n",
    "    \n",
    "    print(f\"\\nüéØ Ready for development and testing!\")\n",
    "\n",
    "# Helper functions for development workflow\n",
    "def quick_development_check():\n",
    "    \"\"\"Quick check of development status.\"\"\"\n",
    "    print(\"üöÄ Quick Development Status Check\\n\")\n",
    "    \n",
    "    # Check sync status\n",
    "    print(\"1. Checking sync status...\")\n",
    "    sync_status = sync_status_check()\n",
    "    \n",
    "    # Validate components\n",
    "    print(\"\\n2. Validating components...\")\n",
    "    validation_results = validate_fastapi_imports()\n",
    "    \n",
    "    # Development summary\n",
    "    print(\"\\n3. Development summary...\")\n",
    "    development_summary()\n",
    "    \n",
    "    print(\"\\nüéâ Development check completed!\")\n",
    "    return {\n",
    "        'sync_status': sync_status,\n",
    "        'validation_results': validation_results\n",
    "    }\n",
    "\n",
    "def extract_cell_code(cell_number: int) -> str:\n",
    "    \"\"\"Extract code from a specific notebook cell.\"\"\"\n",
    "    # This is a placeholder - in a real implementation, you'd parse the notebook JSON\n",
    "    print(f\"üìÑ Extracting code from cell {cell_number}...\")\n",
    "    print(\"‚ö†Ô∏è  Manual extraction required - copy code from notebook cell\")\n",
    "    return \"\"\n",
    "\n",
    "print(\"‚úÖ Code Export Helper loaded successfully\")\n",
    "print(\"üîÑ Functions: compare_files(), export_to_fastapi(), sync_status_check()\")\n",
    "print(\"üìÅ File mappings configured for all components\")\n",
    "print(\"\\nüí° Usage:\")\n",
    "print(\"  - sync_status_check(): Check sync status of all components\")\n",
    "print(\"  - quick_development_check(): Run development status check\")\n",
    "print(\"  - validate_fastapi_imports(): Test FastAPI imports\")\n",
    "print(\"  - development_summary(): Show current environment status\")\n",
    "\n",
    "# Run quick check\n",
    "result = quick_development_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Modern Development Workflow Summary\n\nThis notebook now serves as an **interactive testing and analysis environment** that imports and uses actual FastAPI production modules.\n\n## **New FastAPI-First Architecture**\n\n### **FastAPI Development** (Primary)\n```bash\n# Start development server with hot reload\nuvicorn src.main:app --reload --port 8000\n\n# Run tests continuously\npytest --watch tests/\n\n# Make changes directly in FastAPI codebase\n# Changes are immediately available in notebook\n```\n\n### **Notebook Role** (Supporting)\n1. **Interactive Testing**: Test production modules with real data\n2. **Data Analysis**: Analyze entity extraction quality and results\n3. **Graph Exploration**: Query Neo4j interactively\n4. **Prompt Engineering**: Experiment with OpenAI prompts\n\n## **Benefits Achieved**\n\n‚úÖ **Single Source of Truth**: All logic lives in FastAPI only  \n‚úÖ **Zero Code Duplication**: Notebook imports production modules  \n‚úÖ **Instant Synchronization**: Changes in FastAPI immediately available  \n‚úÖ **Real Testing**: Notebook tests actual production behavior  \n‚úÖ **Reduced Maintenance**: No need to sync two codebases  \n‚úÖ **Faster Development**: Hot reload + immediate notebook feedback  \n\n## **Development Workflow**\n\n### **1. Primary Development in FastAPI**\n- Edit code in `src/` directory\n- Use `uvicorn --reload` for instant feedback\n- Write and run unit tests with pytest\n- Use debugger and logging for exploration\n\n### **2. Interactive Testing in Notebook** \n- Import updated FastAPI modules automatically\n- Test with real newsletter data\n- Analyze entity extraction results\n- Visualize Neo4j graph data\n- Experiment with prompts and configurations\n\n### **3. Quality Assurance**\n- All tests in `tests/` directory validate production code\n- Notebook testing supplements unit tests with real data\n- Entity extraction tests ensure production reliability\n\n## **Next Steps**\n\n1. **Start FastAPI Development**: `uvicorn src.main:app --reload --port 8000`\n2. **Run Tests**: `pytest --watch tests/`\n3. **Use Notebook for Analysis**: Import modules and test interactively\n4. **Deploy Changes**: Push to production knowing notebook validates behavior\n\n## **File Structure**\n```\nsrc/                          # Production code (single source of truth)\n‚îú‚îÄ‚îÄ processors/\n‚îÇ   ‚îú‚îÄ‚îÄ entity_extractor.py   # Production entity extraction\n‚îÇ   ‚îî‚îÄ‚îÄ html_processor.py     # Production HTML processing\n‚îú‚îÄ‚îÄ graph/\n‚îÇ   ‚îî‚îÄ‚îÄ neo4j_client.py       # Production Neo4j client\n‚îî‚îÄ‚îÄ workflows/\n    ‚îî‚îÄ‚îÄ newsletter_processor.py # Production workflow\n\ntests/                        # Comprehensive test suite\n‚îú‚îÄ‚îÄ test_entity_extractor.py  # Entity extraction tests\n‚îú‚îÄ‚îÄ test_newsletter.py        # Integration tests\n‚îî‚îÄ‚îÄ test_simple.py           # Basic functionality tests\n\nnotebooks/                    # Interactive analysis only\n‚îî‚îÄ‚îÄ newsletter_development.ipynb # This notebook (imports from src/)\n```\n\n**üéØ The notebook is now a consumer of production code, not a parallel implementation!**"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}