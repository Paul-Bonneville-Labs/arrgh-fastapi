{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newsletter Development Notebook\n",
    "\n",
    "This notebook provides a complete 1:1 correspondence with the FastAPI newsletter processing system for rapid development and testing.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "### Environment Configuration\n",
    "1. **Copy the environment template**: `cp .env.example .env.local`\n",
    "2. **Configure your credentials** in `.env.local`:\n",
    "   ```bash\n",
    "   # LLM Configuration\n",
    "   OPENAI_API_KEY=sk-your-openai-api-key-here\n",
    "   \n",
    "   # Neo4j Configuration  \n",
    "   NEO4J_URI=bolt://localhost:7687\n",
    "   NEO4J_USER=neo4j\n",
    "   NEO4J_PASSWORD=your-neo4j-password\n",
    "   \n",
    "   # Processing Configuration\n",
    "   ENTITY_CONFIDENCE_THRESHOLD=0.7\n",
    "   FACT_CONFIDENCE_THRESHOLD=0.8\n",
    "   ```\n",
    "\n",
    "### Required Dependencies\n",
    "```bash\n",
    "# Core dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Notebook development dependencies\n",
    "pip install -r requirements-notebook.txt\n",
    "```\n",
    "\n",
    "### Neo4j Setup\n",
    "```bash\n",
    "# Start Neo4j for development\n",
    "./scripts/start-neo4j.sh\n",
    "\n",
    "# Access Neo4j Browser: http://localhost:7474\n",
    "# Username: neo4j, Password: your-neo4j-password\n",
    "```\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "This notebook mirrors the complete FastAPI application structure:\n",
    "\n",
    "| **Notebook Cell** | **FastAPI File** | **Purpose** |\n",
    "|-------------------|------------------|-------------|\n",
    "| Cell 1 | `src/config.py` | Environment configuration |\n",
    "| Cell 2 | `src/models/newsletter.py` | Data models |\n",
    "| Cell 3 | `src/processors/html_processor.py` | HTML processing |\n",
    "| Cell 4 | `src/processors/entity_extractor.py` | Entity extraction |\n",
    "| Cell 5 | `src/graph/neo4j_client.py` | Neo4j operations |\n",
    "| Cell 6 | `src/workflows/newsletter_processor.py` | Complete workflow |\n",
    "| Cell 7 | Testing & Validation | Pipeline testing |\n",
    "| Cell 8 | Code Export Helper | Sync back to FastAPI |\n",
    "\n",
    "## Security Notes\n",
    "\n",
    "- **Never commit credentials**: The notebook uses `.env.local` which is gitignored\n",
    "- **Environment variables**: All sensitive data is loaded from environment variables\n",
    "- **Local development**: This setup is designed for local development only\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. Set up environment variables as described above\n",
    "2. Run cells 1-5 to initialize all components\n",
    "3. Run cell 7 to test the complete pipeline\n",
    "4. Use cell 8 to export code back to FastAPI files\n",
    "\n",
    "## Entity Types\n",
    "\n",
    "The system extracts 6 types of entities:\n",
    "- **Organization**: Companies, institutions, government bodies\n",
    "- **Person**: Individuals mentioned in content\n",
    "- **Product**: Software, hardware, services, models\n",
    "- **Event**: Conferences, announcements, launches\n",
    "- **Location**: Geographic locations\n",
    "- **Topic**: Subject areas, technologies, fields of study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup and Configuration\n",
    "\n",
    "**FastAPI File**: `/Users/paulbonneville/Developer/arrgh-fastapi/src/config.py`\n",
    "\n",
    "**Purpose**: Environment configuration and dependency management for the notebook.\n",
    "\n",
    "**What this mirrors**: The complete configuration system from the FastAPI app, including:\n",
    "- `get_settings()` - Load configuration from environment variables\n",
    "- `print_configuration_summary()` - Display current configuration\n",
    "- `validate_configuration()` - Validate configuration completeness\n",
    "- Environment variable management with .env.local for development\n",
    "- Fallback configuration class for when FastAPI imports are unavailable\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuration Summary:\n",
      "  Environment: local\n",
      "  Config File: .env.local\n",
      "  LLM Model: gpt-4-turbo\n",
      "  Neo4j URI: bolt://localhost:7687\n",
      "  API Host: 0.0.0.0:8000\n",
      "  Log Level: DEBUG\n",
      "  Debug Mode: True\n",
      "  Metrics Enabled: True\n",
      "  Max Entities: 100\n",
      "  Entity Confidence Threshold: 0.7\n",
      "  Fact Confidence Threshold: 0.8\n",
      "\n",
      "üìã Configuration Messages:\n",
      "  WARNING: Neo4j password not properly configured\n",
      "  INFO: Debug mode is enabled\n",
      "  INFO: Debug logging is enabled\n",
      "\n",
      "‚ö†Ô∏è  Configuration Issues:\n",
      "  INFO: Debug mode is enabled\n",
      "  INFO: Debug logging is enabled\n",
      "\n",
      "‚úÖ Using FastAPI configuration system\n",
      "\n",
      "üîç Environment Status:\n",
      "  Project root: /Users/paulbonneville/Developer/arrgh-fastapi\n",
      "  Environment: local\n",
      "  Python path includes src: True\n",
      "\n",
      "‚úÖ OpenAI API key configured (starts with: sk-svca...)\n",
      "‚úÖ Neo4j configured and connected: bolt://localhost:7687\n",
      "\n",
      "üì¶ Loading dependencies...\n",
      "‚úÖ HTML processing libraries loaded\n",
      "‚úÖ OpenAI library loaded\n",
      "‚úÖ Neo4j library loaded\n",
      "‚úÖ Structlog library loaded\n",
      "\n",
      "‚úÖ Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Environment Setup and Configuration\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Add src directory to path for imports\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\n",
    "src_path = project_root / 'src'\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / \".env.local\")  # Use .env.local for development\n",
    "\n",
    "# Import the proper configuration system from FastAPI\n",
    "try:\n",
    "    from config import get_settings, print_configuration_summary, validate_configuration\n",
    "    \n",
    "    # Get configuration using the FastAPI system\n",
    "    config = get_settings()\n",
    "    \n",
    "    # Print configuration summary\n",
    "    print_configuration_summary(config)\n",
    "    \n",
    "    # Validate configuration (but filter out Neo4j warning if it's actually working)\n",
    "    validation_messages = validate_configuration(config)\n",
    "    \n",
    "    # Test Neo4j connection to verify if the password actually works\n",
    "    neo4j_working = False\n",
    "    if config.neo4j_password:\n",
    "        try:\n",
    "            from neo4j import GraphDatabase\n",
    "            driver = GraphDatabase.driver(config.neo4j_uri, auth=(config.neo4j_user, config.neo4j_password))\n",
    "            with driver.session() as session:\n",
    "                session.run(\"RETURN 1 as test\")\n",
    "            driver.close()\n",
    "            neo4j_working = True\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Filter out Neo4j password warning if connection works\n",
    "    if neo4j_working:\n",
    "        validation_messages = [msg for msg in validation_messages if \"Neo4j password\" not in msg]\n",
    "    \n",
    "    if validation_messages:\n",
    "        print(\"\\n‚ö†Ô∏è  Configuration Issues:\")\n",
    "        for message in validation_messages:\n",
    "            print(f\"  {message}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Configuration is valid\")\n",
    "        \n",
    "    print(\"\\n‚úÖ Using FastAPI configuration system\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Could not import FastAPI config system: {e}\")\n",
    "    print(\"  Falling back to simple config class...\")\n",
    "    \n",
    "    # Fallback configuration class\n",
    "    class Config:\n",
    "        \"\"\"Configuration class mirroring src/config.py Settings.\"\"\"\n",
    "        \n",
    "        # LLM Configuration\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        llm_model = os.getenv(\"LLM_MODEL\", \"gpt-4-turbo\")\n",
    "        llm_temperature = float(os.getenv(\"LLM_TEMPERATURE\", \"0.1\"))\n",
    "        llm_max_tokens = int(os.getenv(\"LLM_MAX_TOKENS\", \"2000\"))\n",
    "        \n",
    "        # Neo4j Configuration\n",
    "        neo4j_uri = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "        neo4j_user = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "        neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "        neo4j_database = os.getenv(\"NEO4J_DATABASE\", \"neo4j\")\n",
    "        \n",
    "        # Processing Configuration\n",
    "        max_entities_per_newsletter = int(os.getenv(\"MAX_ENTITIES_PER_NEWSLETTER\", \"100\"))\n",
    "        fact_extraction_batch_size = int(os.getenv(\"FACT_EXTRACTION_BATCH_SIZE\", \"10\"))\n",
    "        processing_timeout = int(os.getenv(\"PROCESSING_TIMEOUT\", \"300\"))\n",
    "        entity_confidence_threshold = float(os.getenv(\"ENTITY_CONFIDENCE_THRESHOLD\", \"0.7\"))\n",
    "        fact_confidence_threshold = float(os.getenv(\"FACT_CONFIDENCE_THRESHOLD\", \"0.8\"))\n",
    "        \n",
    "        # Feature Flags\n",
    "        enable_debug_mode = os.getenv(\"ENABLE_DEBUG_MODE\", \"false\").lower() == \"true\"\n",
    "        enable_async_processing = os.getenv(\"ENABLE_ASYNC_PROCESSING\", \"false\").lower() == \"true\"\n",
    "        \n",
    "        # Security Configuration\n",
    "        secret_key = os.getenv(\"SECRET_KEY\")\n",
    "    \n",
    "    config = Config()\n",
    "    neo4j_working = False\n",
    "    \n",
    "    # Test Neo4j connection\n",
    "    if config.neo4j_password:\n",
    "        try:\n",
    "            from neo4j import GraphDatabase\n",
    "            driver = GraphDatabase.driver(config.neo4j_uri, auth=(config.neo4j_user, config.neo4j_password))\n",
    "            with driver.session() as session:\n",
    "                session.run(\"RETURN 1 as test\")\n",
    "            driver.close()\n",
    "            neo4j_working = True\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Basic validation\n",
    "    validation_messages = []\n",
    "    if not config.openai_api_key or config.openai_api_key.startswith(\"sk-your-\"):\n",
    "        validation_messages.append(\"‚ö†Ô∏è OpenAI API key not properly configured\")\n",
    "    if not neo4j_working:\n",
    "        validation_messages.append(\"‚ö†Ô∏è Neo4j connection failed - check password and service\")\n",
    "    \n",
    "    print(\"üîß Configuration loaded from environment:\")\n",
    "    print(f\"  Environment file: .env.local\")\n",
    "    print(f\"  LLM Model: {config.llm_model}\")\n",
    "    print(f\"  Neo4j URI: {config.neo4j_uri}\")\n",
    "    print(f\"  Max Entities: {config.max_entities_per_newsletter}\")\n",
    "    print(f\"  Entity Confidence Threshold: {config.entity_confidence_threshold}\")\n",
    "    print(f\"  Debug Mode: {config.enable_debug_mode}\")\n",
    "    \n",
    "    if validation_messages:\n",
    "        print(\"\\nüìã Configuration Messages:\")\n",
    "        for message in validation_messages:\n",
    "            print(f\"  {message}\")\n",
    "\n",
    "# Environment validation\n",
    "print(\"\\nüîç Environment Status:\")\n",
    "print(f\"  Project root: {project_root}\")\n",
    "print(f\"  Environment: {os.getenv('ENVIRONMENT', 'local')}\")\n",
    "print(f\"  Python path includes src: {str(src_path) in sys.path}\")\n",
    "\n",
    "# Critical settings check\n",
    "if not config.openai_api_key or config.openai_api_key.startswith(\"sk-your-\"):\n",
    "    print(\"\\n‚ùå SETUP REQUIRED: Copy .env.example to .env.local and add your OpenAI API key\")\n",
    "    print(\"   cp .env.example .env.local\")\n",
    "    print(\"   # Edit .env.local with your actual API key\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ OpenAI API key configured (starts with: {config.openai_api_key[:7]}...)\")\n",
    "\n",
    "if neo4j_working:\n",
    "    print(f\"‚úÖ Neo4j configured and connected: {config.neo4j_uri}\")\n",
    "else:\n",
    "    print(\"‚ùå SETUP REQUIRED: Configure Neo4j password in .env.local\")\n",
    "    print(\"   # Run: ./scripts/start-neo4j.sh\")\n",
    "    print(\"   # Then add NEO4J_PASSWORD to .env.local\")\n",
    "\n",
    "# Import statements with fallback handling\n",
    "print(\"\\nüì¶ Loading dependencies...\")\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "    import html2text\n",
    "    print(\"‚úÖ HTML processing libraries loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è HTML processing libraries not available: {e}\")\n",
    "    print(\"  Run: pip install beautifulsoup4 html2text\")\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    print(\"‚úÖ OpenAI library loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è OpenAI library not available: {e}\")\n",
    "    print(\"  Run: pip install openai\")\n",
    "\n",
    "try:\n",
    "    from neo4j import GraphDatabase\n",
    "    print(\"‚úÖ Neo4j library loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Neo4j library not available: {e}\")\n",
    "    print(\"  Run: pip install neo4j\")\n",
    "\n",
    "try:\n",
    "    import structlog\n",
    "    print(\"‚úÖ Structlog library loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Structlog library not available: {e}\")\n",
    "    print(\"  Run: pip install structlog\")\n",
    "\n",
    "print(\"\\n‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Models (Pydantic)\n",
    "\n",
    "**FastAPI File**: `/Users/paulbonneville/Developer/arrgh-fastapi/src/models/newsletter.py`\n",
    "\n",
    "**Purpose**: Data model definitions using Pydantic for type validation and serialization.\n",
    "\n",
    "**What this mirrors**: The complete data model system from the FastAPI app, including:\n",
    "- `Entity` - Represents extracted entities with name, type, confidence, and context\n",
    "- `Fact` - Represents relationships between entities with temporal context\n",
    "- `Newsletter` - Core newsletter data structure with HTML content and metadata\n",
    "- `NewsletterProcessingRequest` - API request model for newsletter processing\n",
    "- `NewsletterProcessingResponse` - API response model with processing results and metrics\n",
    "- `ExtractionState` - Internal state management for the processing workflow\n",
    "- All Pydantic field validators and default factories\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pydantic imported successfully\n",
      "üìä Data models defined successfully!\n",
      "  - Entity: Represents an extracted entity from newsletter content.\n",
      "  - Newsletter: Represents a newsletter to be processed.\n",
      "  - NewsletterProcessingResponse: Response model for newsletter processing endpoint.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Models\n",
    "from typing import Optional, List, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Import pydantic with fallback\n",
    "try:\n",
    "    from pydantic import BaseModel, Field\n",
    "    print(\"‚úÖ Pydantic imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Pydantic import failed: {e}\")\n",
    "    print(\"  Run: pip install pydantic\")\n",
    "    # Create a simple BaseModel fallback\n",
    "    class BaseModel:\n",
    "        def __init__(self, **kwargs):\n",
    "            for key, value in kwargs.items():\n",
    "                setattr(self, key, value)\n",
    "    def Field(**kwargs):\n",
    "        return None\n",
    "\n",
    "# Data models mirroring src/models/newsletter.py\n",
    "class Entity(BaseModel):\n",
    "    \"\"\"Represents an extracted entity from newsletter content.\"\"\"\n",
    "    name: str\n",
    "    type: str  # Organization, Person, Product, Event, Location, Topic\n",
    "    aliases: List[str] = Field(default_factory=list)\n",
    "    confidence: float = Field(ge=0.0, le=1.0)\n",
    "    context: Optional[str] = None\n",
    "    properties: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "class Fact(BaseModel):\n",
    "    \"\"\"Represents a relationship or fact between entities.\"\"\"\n",
    "    subject_entity: str\n",
    "    predicate: str  # relationship type\n",
    "    object_entity: str\n",
    "    confidence: float = Field(ge=0.0, le=1.0)\n",
    "    temporal_context: Optional[str] = None\n",
    "    date_mentioned: Optional[datetime] = None\n",
    "    source_context: Optional[str] = None\n",
    "\n",
    "class Newsletter(BaseModel):\n",
    "    \"\"\"Represents a newsletter to be processed.\"\"\"\n",
    "    html_content: str\n",
    "    subject: str\n",
    "    sender: str\n",
    "    received_date: Optional[datetime] = None\n",
    "    newsletter_id: Optional[str] = None\n",
    "\n",
    "class NewsletterProcessingRequest(BaseModel):\n",
    "    \"\"\"Request model for newsletter processing endpoint.\"\"\"\n",
    "    html_content: str\n",
    "    subject: str\n",
    "    sender: str\n",
    "    received_date: Optional[datetime] = None\n",
    "\n",
    "class NewsletterProcessingResponse(BaseModel):\n",
    "    \"\"\"Response model for newsletter processing endpoint.\"\"\"\n",
    "    status: str\n",
    "    newsletter_id: str\n",
    "    processing_time: float\n",
    "    entities_extracted: int\n",
    "    entities_new: int\n",
    "    entities_updated: int\n",
    "    entity_summary: Dict[str, int]\n",
    "    text_summary: str\n",
    "    errors: List[str] = Field(default_factory=list)\n",
    "\n",
    "class ExtractionState(BaseModel):\n",
    "    \"\"\"State for the processing workflow.\"\"\"\n",
    "    # Input\n",
    "    newsletter: Newsletter\n",
    "    \n",
    "    # Processing stages\n",
    "    cleaned_text: str = \"\"\n",
    "    extracted_entities: List[Entity] = Field(default_factory=list)\n",
    "    resolved_entities: List[Entity] = Field(default_factory=list)\n",
    "    extracted_facts: List[Fact] = Field(default_factory=list)\n",
    "    \n",
    "    # Results\n",
    "    neo4j_updates: Dict[str, Any] = Field(default_factory=dict)\n",
    "    processing_metrics: Dict[str, Any] = Field(default_factory=dict)\n",
    "    text_summary: str = \"\"\n",
    "    errors: List[str] = Field(default_factory=list)\n",
    "    \n",
    "    # Metadata\n",
    "    processing_start_time: datetime = Field(default_factory=datetime.now)\n",
    "    current_step: str = \"initialized\"\n",
    "\n",
    "print(\"üìä Data models defined successfully!\")\n",
    "print(f\"  - Entity: {Entity.__doc__}\")\n",
    "print(f\"  - Newsletter: {Newsletter.__doc__}\")\n",
    "print(f\"  - NewsletterProcessingResponse: {NewsletterProcessingResponse.__doc__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Processor (BeautifulSoup)\n",
    "\n",
    "**FastAPI File**: `/Users/paulbonneville/Developer/arrgh-fastapi/src/processors/html_processor.py`\n",
    "\n",
    "**Purpose**: HTML content processing and text extraction for newsletter analysis.\n",
    "\n",
    "**What this mirrors**: The complete HTML processing system from the FastAPI app, including:\n",
    "- `HTMLProcessor` class - Main processor for HTML content cleaning and parsing\n",
    "- `clean_html()` - Removes HTML tags and extracts clean readable text\n",
    "- `extract_text_sections()` - Structured extraction of headers, paragraphs, links, and lists\n",
    "- BeautifulSoup parsing with script/style element removal\n",
    "- Whitespace normalization and text cleaning algorithms\n",
    "- Structured logging for processing metrics and debugging\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HTML Processor loaded successfully\n",
      "üìÑ Functions: clean_html(), extract_text_sections()\n",
      "\u001b[2m2025-07-09 21:57:01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTML content cleaned          \u001b[0m \u001b[36mcleaned_length\u001b[0m=\u001b[35m29\u001b[0m \u001b[36moriginal_length\u001b[0m=\u001b[35m71\u001b[0m\n",
      "üß™ Test: Cleaned 71 chars to 29 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: HTML Processor (‚Üí )\n",
    "import structlog\n",
    "\n",
    "class HTMLProcessor:\n",
    "    \"\"\"Process HTML content from newsletters.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = structlog.get_logger()\n",
    "        \n",
    "    def clean_html(self, html_content: str) -> str:\n",
    "        \"\"\"Clean HTML content and extract readable text.\"\"\"\n",
    "        try:\n",
    "            # Parse HTML\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            \n",
    "            # Remove script and style elements\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            \n",
    "            # Get text\n",
    "            text = soup.get_text()\n",
    "            \n",
    "            # Clean up whitespace\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "            \n",
    "            self.logger.info(\"HTML content cleaned\", \n",
    "                           original_length=len(html_content),\n",
    "                           cleaned_length=len(text))\n",
    "            \n",
    "            return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error cleaning HTML\", error=str(e))\n",
    "            return html_content\n",
    "    \n",
    "    def extract_text_sections(self, html_content: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract structured text sections from HTML.\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            \n",
    "            # Remove script and style elements\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            \n",
    "            # Extract headers\n",
    "            headers = []\n",
    "            for header in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "                text = header.get_text().strip()\n",
    "                if text:\n",
    "                    headers.append({\n",
    "                        'level': header.name,\n",
    "                        'text': text\n",
    "                    })\n",
    "            \n",
    "            # Extract paragraphs\n",
    "            paragraphs = []\n",
    "            for p in soup.find_all('p'):\n",
    "                text = p.get_text().strip()\n",
    "                if text and len(text) > 20:  # Filter out short paragraphs\n",
    "                    paragraphs.append(text)\n",
    "            \n",
    "            # Extract links\n",
    "            links = []\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                text = link.get_text().strip()\n",
    "                href = link['href']\n",
    "                if text and href:\n",
    "                    links.append({\n",
    "                        'text': text,\n",
    "                        'url': href\n",
    "                    })\n",
    "            \n",
    "            # Extract lists\n",
    "            lists = []\n",
    "            for ul in soup.find_all(['ul', 'ol']):\n",
    "                items = []\n",
    "                for li in ul.find_all('li'):\n",
    "                    text = li.get_text().strip()\n",
    "                    if text:\n",
    "                        items.append(text)\n",
    "                if items:\n",
    "                    lists.append({\n",
    "                        'type': ul.name,\n",
    "                        'items': items\n",
    "                    })\n",
    "            \n",
    "            result = {\n",
    "                'headers': headers,\n",
    "                'paragraphs': paragraphs,\n",
    "                'links': links,\n",
    "                'lists': lists\n",
    "            }\n",
    "            \n",
    "            self.logger.info(\"Text sections extracted\", \n",
    "                           headers_count=len(headers),\n",
    "                           paragraphs_count=len(paragraphs),\n",
    "                           links_count=len(links),\n",
    "                           lists_count=len(lists))\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error extracting text sections\", error=str(e))\n",
    "            return {\n",
    "                'headers': [],\n",
    "                'paragraphs': [],\n",
    "                'links': [],\n",
    "                'lists': []\n",
    "            }\n",
    "\n",
    "# Initialize HTML processor\n",
    "html_processor = HTMLProcessor()\n",
    "\n",
    "print(\"‚úÖ HTML Processor loaded successfully\")\n",
    "print(\"üìÑ Functions: clean_html(), extract_text_sections()\")\n",
    "\n",
    "# Test with sample HTML\n",
    "sample_html = \"<html><body><h1>Test</h1><p>This is a test paragraph.</p></body></html>\"\n",
    "test_cleaned = html_processor.clean_html(sample_html)\n",
    "print(f\"üß™ Test: Cleaned {len(sample_html)} chars to {len(test_cleaned)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extractor (OpenAI + Pydantic)\n",
    "\n",
    "**FastAPI File**: `/Users/paulbonneville/Developer/arrgh-fastapi/src/processors/entity_extractor.py`\n",
    "\n",
    "**Purpose**: Entity extraction using OpenAI LLM with structured JSON output and confidence scoring.\n",
    "\n",
    "**What this mirrors**: The complete entity extraction system from the FastAPI app, including:\n",
    "- `EntityExtractor` class - Main class for LLM-based entity extraction\n",
    "- `ENTITY_EXTRACTION_PROMPT` - Detailed prompt template for structured entity extraction\n",
    "- `extract_entities()` - Core extraction method with JSON parsing and error handling\n",
    "- OpenAI client initialization and configuration management\n",
    "- JSON parsing fixes for production bug (code block removal, brace matching)\n",
    "- Entity filtering by confidence threshold and validation\n",
    "- Support for 6 entity types: Organization, Person, Product, Event, Location, Topic\n",
    "- Structured logging and comprehensive error handling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Cell 4: Entity Extractor\n",
      "‚úÖ OpenAI client initialized successfully with explicit proxy avoidance\n",
      "‚úÖ OpenAI test call successful: Hello, I am working!\n",
      "üîç Testing entity extraction...\n",
      "‚úÖ Extracted 7 entities:\n",
      "  1. OpenAI (Organization) - Confidence: 0.99\n",
      "  2. GPT-4 (Product) - Confidence: 0.98\n",
      "  3. San Francisco (Location) - Confidence: 0.95\n",
      "  4. Sam Altman (Person) - Confidence: 0.97\n",
      "  5. OpenAI DevDay 2024 (Event) - Confidence: 0.95\n",
      "\n",
      "‚úÖ Entity extraction setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Entity Extractor (‚Üí ../src/processors/entity_extractor.py)\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "print(\"üß™ Testing Cell 4: Entity Extractor\")\n",
    "\n",
    "# ULTRAFIX: Initialize OpenAI client with explicit proxy avoidance\n",
    "openai_client = None\n",
    "if config.openai_api_key and not config.openai_api_key.startswith(\"sk-your-\"):\n",
    "    try:\n",
    "        # Clear any potential proxy environment variables that might interfere\n",
    "        import os\n",
    "        old_env = {}\n",
    "        proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'ALL_PROXY', 'http_proxy', 'https_proxy', 'all_proxy']\n",
    "        for var in proxy_vars:\n",
    "            if var in os.environ:\n",
    "                old_env[var] = os.environ[var]\n",
    "                del os.environ[var]\n",
    "        \n",
    "        from openai import OpenAI\n",
    "        import httpx\n",
    "        \n",
    "        # Create httpx client explicitly without proxy to avoid parameter mismatch\n",
    "        http_client = httpx.Client(\n",
    "            timeout=30.0,\n",
    "            proxy=None,  # Explicitly set to None to avoid proxy issues\n",
    "            trust_env=False  # Don't trust environment variables for proxy config\n",
    "        )\n",
    "        \n",
    "        # Initialize OpenAI client with explicit http_client\n",
    "        openai_client = OpenAI(\n",
    "            api_key=config.openai_api_key,\n",
    "            http_client=http_client\n",
    "        )\n",
    "        \n",
    "        # Restore environment variables\n",
    "        for var, value in old_env.items():\n",
    "            os.environ[var] = value\n",
    "        \n",
    "        print(\"‚úÖ OpenAI client initialized successfully with explicit proxy avoidance\")\n",
    "        \n",
    "        # Test the client with a simple call\n",
    "        test_response = openai_client.chat.completions.create(\n",
    "            model=config.llm_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Say 'Hello, I am working!'\"}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ OpenAI test call successful: {test_response.choices[0].message.content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå OpenAI client initialization failed: {e}\")\n",
    "        print(f\"  Error type: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        openai_client = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è OpenAI API key not configured properly\")\n",
    "    print(\"  Make sure OPENAI_API_KEY is set in your .env.local file\")\n",
    "\n",
    "# Entity extraction prompt template (mirroring FastAPI exactly)\n",
    "ENTITY_EXTRACTION_PROMPT = \"\"\"\n",
    "You are an expert at extracting structured information from newsletter content. \n",
    "Extract entities from the following newsletter text and classify them into these categories:\n",
    "\n",
    "**Entity Types:**\n",
    "- **Organization**: Companies, institutions, government bodies\n",
    "- **Person**: Individuals mentioned in content\n",
    "- **Product**: Software, hardware, services, models\n",
    "- **Event**: Conferences, announcements, launches\n",
    "- **Location**: Geographic locations (cities, countries, regions)\n",
    "- **Topic**: Subject areas, technologies, fields of study\n",
    "\n",
    "**Instructions:**\n",
    "1. Extract entities with high confidence (>0.7)\n",
    "2. Provide alternative names/aliases if mentioned\n",
    "3. Include context where the entity was mentioned\n",
    "4. Rate confidence from 0.0 to 1.0\n",
    "5. Return results as valid JSON\n",
    "\n",
    "**Newsletter Content:**\n",
    "{content}\n",
    "\n",
    "**Required JSON Format:**\n",
    "```json\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\n",
    "      \"name\": \"Entity Name\",\n",
    "      \"type\": \"Organization|Person|Product|Event|Location|Topic\",\n",
    "      \"aliases\": [\"Alternative Name 1\", \"Alternative Name 2\"],\n",
    "      \"confidence\": 0.95,\n",
    "      \"context\": \"The sentence or phrase where this entity was mentioned\",\n",
    "      \"properties\": {{\n",
    "        \"additional_info\": \"any relevant details\"\n",
    "      }}\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "Return only valid JSON, no additional text.\n",
    "\"\"\"\n",
    "\n",
    "def extract_entities_from_text(content: str) -> List[Entity]:\n",
    "    \"\"\"\n",
    "    Extract entities from content using OpenAI.\n",
    "    \n",
    "    This function mirrors the logic in src/processors/entity_extractor.py\n",
    "    but includes the JSON parsing fix for the production bug.\n",
    "    \"\"\"\n",
    "    if not openai_client:\n",
    "        print(\"‚ö†Ô∏è OpenAI client not available - check API key configuration\")\n",
    "        return []\n",
    "    \n",
    "    if not content.strip():\n",
    "        print(\"‚ö†Ô∏è Empty content provided\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Create the completion request (matching FastAPI parameters exactly)\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=config.llm_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert entity extraction assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": ENTITY_EXTRACTION_PROMPT.format(content=content[:3000])}\n",
    "            ],\n",
    "            temperature=config.llm_temperature,\n",
    "            max_tokens=config.llm_max_tokens\n",
    "        )\n",
    "        \n",
    "        # Get the response content\n",
    "        result_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Handle JSON parsing with the production bug fix\n",
    "        # Remove code block markers if present\n",
    "        if '```json' in result_text:\n",
    "            json_match = re.search(r'```json\\s*(.*?)\\s*```', result_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                result_text = json_match.group(1).strip()\n",
    "        elif '```' in result_text:\n",
    "            json_match = re.search(r'```\\s*(.*?)\\s*```', result_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                result_text = json_match.group(1).strip()\n",
    "        \n",
    "        # Parse JSON with enhanced error handling (matching FastAPI fix)\n",
    "        try:\n",
    "            result = json.loads(result_text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ö†Ô∏è JSON parsing failed: {e}\")\n",
    "            # Try to find JSON object in the response\n",
    "            if not result_text.startswith('{'):\n",
    "                start_idx = result_text.find('{')\n",
    "                if start_idx != -1:\n",
    "                    # Find the matching closing brace\n",
    "                    brace_count = 0\n",
    "                    end_idx = start_idx\n",
    "                    for i, char in enumerate(result_text[start_idx:], start_idx):\n",
    "                        if char == '{':\n",
    "                            brace_count += 1\n",
    "                        elif char == '}':\n",
    "                            brace_count -= 1\n",
    "                            if brace_count == 0:\n",
    "                                end_idx = i + 1\n",
    "                                break\n",
    "                    \n",
    "                    if end_idx > start_idx:\n",
    "                        result_text = result_text[start_idx:end_idx]\n",
    "                        result = json.loads(result_text)\n",
    "                    else:\n",
    "                        raise e\n",
    "                else:\n",
    "                    raise e\n",
    "            else:\n",
    "                raise e\n",
    "        \n",
    "        # Convert to Entity objects\n",
    "        entities = []\n",
    "        for entity_data in result.get('entities', []):\n",
    "            # Validate required fields\n",
    "            if not entity_data.get('name') or not entity_data.get('type'):\n",
    "                continue\n",
    "            \n",
    "            # Filter by confidence threshold\n",
    "            confidence = entity_data.get('confidence', 0.0)\n",
    "            if confidence < config.entity_confidence_threshold:\n",
    "                continue\n",
    "            \n",
    "            entity = Entity(\n",
    "                name=entity_data['name'],\n",
    "                type=entity_data['type'],\n",
    "                aliases=entity_data.get('aliases', []),\n",
    "                confidence=confidence,\n",
    "                context=entity_data.get('context'),\n",
    "                properties=entity_data.get('properties', {})\n",
    "            )\n",
    "            entities.append(entity)\n",
    "        \n",
    "        return entities\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Entity extraction failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test function\n",
    "def test_entity_extraction():\n",
    "    \"\"\"Test the entity extraction function.\"\"\"\n",
    "    test_content = \"\"\"\n",
    "    OpenAI announced GPT-4 at their developer conference in San Francisco. \n",
    "    CEO Sam Altman presented the new capabilities during the OpenAI DevDay 2024 event.\n",
    "    Microsoft expanded their Azure AI services with enterprise features.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç Testing entity extraction...\")\n",
    "    entities = extract_entities_from_text(test_content)\n",
    "    \n",
    "    if entities:\n",
    "        print(f\"‚úÖ Extracted {len(entities)} entities:\")\n",
    "        for i, entity in enumerate(entities[:5]):  # Show first 5\n",
    "            print(f\"  {i+1}. {entity.name} ({entity.type}) - Confidence: {entity.confidence}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No entities extracted\")\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Run test if OpenAI is available\n",
    "if openai_client:\n",
    "    test_entities = test_entity_extraction()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping entity extraction test - OpenAI client not available\")\n",
    "    test_entities = []\n",
    "\n",
    "print(\"\\n‚úÖ Entity extraction setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Neo4j connection established\n",
      "\n",
      "üìä Current graph statistics:\n",
      "  Organizations: 6\n",
      "  People: 3\n",
      "  Products: 3\n",
      "  Events: 3\n",
      "  Locations: 2\n",
      "  Topics: 2\n",
      "  Newsletters: 11\n",
      "  Relationships: 29\n",
      "‚úÖ Test query result: Neo4j is working!\n",
      "\n",
      "‚úÖ Neo4j client setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Neo4j Client (‚Üí ../src/graph/neo4j_client.py)\n",
    "import uuid\n",
    "from typing import Dict, List, Optional, Any\n",
    "from datetime import datetime\n",
    "\n",
    "class Neo4jClient:\n",
    "    \"\"\"Neo4j client for graph database operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, uri: str = None, user: str = None, password: str = None):\n",
    "        \"\"\"Initialize Neo4j client with configuration.\"\"\"\n",
    "        self.uri = uri or config.neo4j_uri\n",
    "        self.user = user or config.neo4j_user\n",
    "        self.password = password or config.neo4j_password\n",
    "        self.driver = None\n",
    "        self.connected = False\n",
    "        \n",
    "    def connect(self) -> bool:\n",
    "        \"\"\"Establish connection to Neo4j database.\"\"\"\n",
    "        try:\n",
    "            self.driver = GraphDatabase.driver(\n",
    "                self.uri,\n",
    "                auth=(self.user, self.password)\n",
    "            )\n",
    "            \n",
    "            # Test connection\n",
    "            with self.driver.session() as session:\n",
    "                result = session.run(\"RETURN 1 as test\")\n",
    "                result.single()\n",
    "            \n",
    "            self.connected = True\n",
    "            print(\"‚úÖ Neo4j connection established\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Neo4j connection failed: {e}\")\n",
    "            print(\"  Check if Neo4j is running and credentials are correct\")\n",
    "            return False\n",
    "    \n",
    "    def disconnect(self):\n",
    "        \"\"\"Close Neo4j connection.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "            self.connected = False\n",
    "            print(\"üîå Neo4j connection closed\")\n",
    "    \n",
    "    def execute_query(self, query: str, parameters: Dict[str, Any] = None) -> List[Dict]:\n",
    "        \"\"\"Execute a Cypher query and return results.\"\"\"\n",
    "        if not self.connected or not self.driver:\n",
    "            print(\"‚ùå No active Neo4j connection\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            with self.driver.session() as session:\n",
    "                result = session.run(query, parameters or {})\n",
    "                return result.data()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Query execution failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_or_update_entity(self, entity: Entity) -> Optional[Dict]:\n",
    "        \"\"\"Create or update an entity node in the graph.\"\"\"\n",
    "        # Convert properties to JSON string to avoid Neo4j type issues\n",
    "        properties_json = None\n",
    "        if entity.properties:\n",
    "            import json\n",
    "            properties_json = json.dumps(entity.properties)\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        MERGE (e:{entity.type} {{name: $name}})\n",
    "        ON CREATE SET \n",
    "            e.created_at = datetime(),\n",
    "            e.confidence = $confidence,\n",
    "            e.aliases = $aliases,\n",
    "            e.mention_count = 1,\n",
    "            e.last_seen = datetime(),\n",
    "            e.properties_json = $properties_json\n",
    "        ON MATCH SET\n",
    "            e.last_seen = datetime(),\n",
    "            e.mention_count = e.mention_count + 1,\n",
    "            e.confidence = CASE \n",
    "                WHEN $confidence > e.confidence THEN $confidence \n",
    "                ELSE e.confidence \n",
    "            END,\n",
    "            e.properties_json = COALESCE($properties_json, e.properties_json)\n",
    "        RETURN e, \n",
    "               CASE WHEN e.created_at = e.last_seen THEN 'created' ELSE 'updated' END as operation\n",
    "        \"\"\"\n",
    "        \n",
    "        parameters = {\n",
    "            'name': entity.name,\n",
    "            'confidence': entity.confidence,\n",
    "            'aliases': entity.aliases,\n",
    "            'properties_json': properties_json\n",
    "        }\n",
    "        \n",
    "        result = self.execute_query(query, parameters)\n",
    "        return result[0] if result else None\n",
    "    \n",
    "    def create_newsletter_node(self, newsletter: Newsletter) -> Optional[Dict]:\n",
    "        \"\"\"Create a newsletter node in the graph.\"\"\"\n",
    "        query = \"\"\"\n",
    "        MERGE (n:Newsletter {id: $newsletter_id})\n",
    "        ON CREATE SET\n",
    "            n.subject = $subject,\n",
    "            n.sender = $sender,\n",
    "            n.received_date = $received_date,\n",
    "            n.created_at = datetime(),\n",
    "            n.content_length = $content_length,\n",
    "            n.processed = true\n",
    "        ON MATCH SET\n",
    "            n.last_processed = datetime(),\n",
    "            n.processed = true\n",
    "        RETURN n\n",
    "        \"\"\"\n",
    "        \n",
    "        parameters = {\n",
    "            'newsletter_id': newsletter.newsletter_id,\n",
    "            'subject': newsletter.subject,\n",
    "            'sender': newsletter.sender,\n",
    "            'received_date': newsletter.received_date.isoformat() if newsletter.received_date else None,\n",
    "            'content_length': len(newsletter.html_content)\n",
    "        }\n",
    "        \n",
    "        result = self.execute_query(query, parameters)\n",
    "        return result[0] if result else None\n",
    "    \n",
    "    def link_entity_to_newsletter(self, entity_name: str, entity_type: str, newsletter_id: str, context: str = None) -> Optional[Dict]:\n",
    "        \"\"\"Create a MENTIONED_IN relationship between entity and newsletter.\"\"\"\n",
    "        query = f\"\"\"\n",
    "        MATCH (e:{entity_type} {{name: $entity_name}})\n",
    "        MATCH (n:Newsletter {{id: $newsletter_id}})\n",
    "        MERGE (e)-[r:MENTIONED_IN]->(n)\n",
    "        ON CREATE SET\n",
    "            r.created_at = datetime(),\n",
    "            r.context = $context,\n",
    "            r.mention_count = 1\n",
    "        ON MATCH SET\n",
    "            r.last_mentioned = datetime(),\n",
    "            r.mention_count = r.mention_count + 1,\n",
    "            r.context = COALESCE($context, r.context)\n",
    "        RETURN r\n",
    "        \"\"\"\n",
    "        \n",
    "        parameters = {\n",
    "            'entity_name': entity_name,\n",
    "            'newsletter_id': newsletter_id,\n",
    "            'context': context\n",
    "        }\n",
    "        \n",
    "        result = self.execute_query(query, parameters)\n",
    "        return result[0] if result else None\n",
    "    \n",
    "    def get_graph_stats(self) -> Dict[str, int]:\n",
    "        \"\"\"Get statistics about the graph database.\"\"\"\n",
    "        query = \"\"\"\n",
    "        CALL {\n",
    "            MATCH (o:Organization) RETURN count(o) as organizations\n",
    "        }\n",
    "        CALL {\n",
    "            MATCH (p:Person) RETURN count(p) as people\n",
    "        }\n",
    "        CALL {\n",
    "            MATCH (pr:Product) RETURN count(pr) as products\n",
    "        }\n",
    "        CALL {\n",
    "            MATCH (e:Event) RETURN count(e) as events\n",
    "        }\n",
    "        CALL {\n",
    "            MATCH (l:Location) RETURN count(l) as locations\n",
    "        }\n",
    "        CALL {\n",
    "            MATCH (t:Topic) RETURN count(t) as topics\n",
    "        }\n",
    "        CALL {\n",
    "            MATCH (n:Newsletter) RETURN count(n) as newsletters\n",
    "        }\n",
    "        CALL {\n",
    "            MATCH ()-[r]->() RETURN count(r) as relationships\n",
    "        }\n",
    "        RETURN organizations, people, products, events, locations, topics, newsletters, relationships\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.execute_query(query)\n",
    "        return result[0] if result else {}\n",
    "\n",
    "# Initialize Neo4j client\n",
    "neo4j_client = Neo4jClient()\n",
    "\n",
    "# Test connection\n",
    "if neo4j_client.connect():\n",
    "    # Display current graph statistics\n",
    "    stats = neo4j_client.get_graph_stats()\n",
    "    print(\"\\nüìä Current graph statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key.capitalize()}: {value}\")\n",
    "    \n",
    "    # Test basic query\n",
    "    test_result = neo4j_client.execute_query(\"RETURN 'Neo4j is working!' as message\")\n",
    "    if test_result:\n",
    "        print(f\"‚úÖ Test query result: {test_result[0]['message']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Neo4j operations will be limited without connection\")\n",
    "\n",
    "print(\"\\n‚úÖ Neo4j client setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newsletter Processor (Complete Workflow)\n",
    "\n",
    "**FastAPI File**: `/Users/paulbonneville/Developer/arrgh-fastapi/src/workflows/newsletter_processor.py`\n",
    "\n",
    "**Purpose**: Complete newsletter processing pipeline orchestrating all components for end-to-end workflow.\n",
    "\n",
    "**What this mirrors**: The complete workflow orchestration from the FastAPI app, including:\n",
    "- `NewsletterProcessor` class - Main orchestrator for the complete processing pipeline\n",
    "- `process_newsletter()` - 5-step workflow: HTML cleaning ‚Üí entity extraction ‚Üí Neo4j storage ‚Üí summary generation\n",
    "- `_generate_text_summary()` - Intelligent summary creation with entity breakdown and metrics\n",
    "- Component integration: HTMLProcessor, EntityExtractor, Neo4jClient coordination\n",
    "- Neo4j graph operations: entity creation/updates, relationship linking, newsletter node management\n",
    "- Performance metrics and processing time tracking\n",
    "- Comprehensive error handling with rollback capabilities\n",
    "- Response generation with detailed processing statistics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Newsletter processor initialized\n",
      "‚úÖ Newsletter Processor loaded successfully\n",
      "üîÑ Complete pipeline: HTML ‚Üí Entities ‚Üí Neo4j ‚Üí Summary\n",
      "üìä Functions: process_newsletter()\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class NewsletterProcessor:\n",
    "    \"\"\"Complete newsletter processing pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, config_obj):\n",
    "        self.config = config_obj\n",
    "        self.html_processor = html_processor\n",
    "        self.openai_client = openai_client\n",
    "        self.neo4j_client = neo4j_client\n",
    "        print(\"‚úÖ Newsletter processor initialized\")\n",
    "    \n",
    "    def process_newsletter(self, newsletter: Newsletter) -> NewsletterProcessingResponse:\n",
    "        \"\"\"Process a newsletter through the complete pipeline.\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        newsletter_id = newsletter.newsletter_id or str(uuid.uuid4())\n",
    "        newsletter.newsletter_id = newsletter_id\n",
    "        \n",
    "        print(f\"üöÄ Starting newsletter processing: {newsletter.subject}\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Clean HTML content\n",
    "            print(\"1Ô∏è‚É£ Processing HTML content...\")\n",
    "            cleaned_text = self.html_processor.clean_html(newsletter.html_content)\n",
    "            text_sections = self.html_processor.extract_text_sections(newsletter.html_content)\n",
    "            print(f\"   ‚úÖ Cleaned text: {len(cleaned_text)} characters\")\n",
    "            \n",
    "            # Step 2: Extract entities\n",
    "            print(\"2Ô∏è‚É£ Extracting entities...\")\n",
    "            entities = extract_entities_from_text(cleaned_text)\n",
    "            print(f\"   ‚úÖ Extracted {len(entities)} entities\")\n",
    "            \n",
    "            # Step 3: Create newsletter node in Neo4j\n",
    "            entities_new = 0\n",
    "            entities_updated = 0\n",
    "            relationships_created = 0\n",
    "            \n",
    "            if self.neo4j_client.connected:\n",
    "                print(\"3Ô∏è‚É£ Creating newsletter node...\")\n",
    "                newsletter_result = self.neo4j_client.create_newsletter_node(newsletter)\n",
    "                if newsletter_result:\n",
    "                    print(\"   ‚úÖ Newsletter node created\")\n",
    "                \n",
    "                # Step 4: Process entities in Neo4j\n",
    "                print(\"4Ô∏è‚É£ Processing entities in graph...\")\n",
    "                for entity in entities:\n",
    "                    try:\n",
    "                        # Create or update entity\n",
    "                        entity_result = self.neo4j_client.create_or_update_entity(entity)\n",
    "                        if entity_result:\n",
    "                            operation = entity_result.get('operation', 'unknown')\n",
    "                            if operation == 'created':\n",
    "                                entities_new += 1\n",
    "                            else:\n",
    "                                entities_updated += 1\n",
    "                            \n",
    "                            # Link to newsletter\n",
    "                            link_result = self.neo4j_client.link_entity_to_newsletter(\n",
    "                                entity.name,\n",
    "                                entity.type,\n",
    "                                newsletter.newsletter_id,\n",
    "                                entity.context\n",
    "                            )\n",
    "                            if link_result:\n",
    "                                relationships_created += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ‚ö†Ô∏è Error processing entity {entity.name}: {e}\")\n",
    "                \n",
    "                print(f\"   ‚úÖ Processed: {entities_new} new, {entities_updated} updated, {relationships_created} linked\")\n",
    "            \n",
    "            # Step 5: Generate summary\n",
    "            print(\"5Ô∏è‚É£ Generating summary...\")\n",
    "            processing_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            # Entity type breakdown\n",
    "            entity_summary = {}\n",
    "            for entity in entities:\n",
    "                entity_summary[entity.type] = entity_summary.get(entity.type, 0) + 1\n",
    "            \n",
    "            # Generate text summary\n",
    "            text_summary = self._generate_text_summary(cleaned_text, entities, text_sections)\n",
    "            \n",
    "            print(f\"   ‚úÖ Processing completed in {processing_time:.2f} seconds\")\n",
    "            \n",
    "            return NewsletterProcessingResponse(\n",
    "                status=\"success\",\n",
    "                newsletter_id=newsletter_id,\n",
    "                processing_time=processing_time,\n",
    "                entities_extracted=len(entities),\n",
    "                entities_new=entities_new,\n",
    "                entities_updated=entities_updated,\n",
    "                entity_summary=entity_summary,\n",
    "                text_summary=text_summary,\n",
    "                errors=[]\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            processing_time = (datetime.now() - start_time).total_seconds()\n",
    "            error_msg = f\"Error processing newsletter: {str(e)}\"\n",
    "            print(f\"‚ùå Pipeline failed: {error_msg}\")\n",
    "            \n",
    "            return NewsletterProcessingResponse(\n",
    "                status=\"error\",\n",
    "                newsletter_id=newsletter_id,\n",
    "                processing_time=processing_time,\n",
    "                entities_extracted=0,\n",
    "                entities_new=0,\n",
    "                entities_updated=0,\n",
    "                entity_summary={},\n",
    "                text_summary=\"\",\n",
    "                errors=[error_msg]\n",
    "            )\n",
    "    \n",
    "    def _generate_text_summary(self, cleaned_text: str, entities: List[Entity], text_sections: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate a text summary of the newsletter.\"\"\"\n",
    "        summary_parts = []\n",
    "        \n",
    "        # Add basic stats\n",
    "        summary_parts.append(f\"Newsletter processed with {len(entities)} entities extracted.\")\n",
    "        \n",
    "        # Add entity type breakdown\n",
    "        entity_types = {}\n",
    "        for entity in entities:\n",
    "            entity_types[entity.type] = entity_types.get(entity.type, 0) + 1\n",
    "        \n",
    "        if entity_types:\n",
    "            type_summary = \", \".join([f\"{count} {entity_type}\" for entity_type, count in entity_types.items()])\n",
    "            summary_parts.append(f\"Entity breakdown: {type_summary}.\")\n",
    "        \n",
    "        # Add content structure info\n",
    "        if text_sections:\n",
    "            structure_info = []\n",
    "            if text_sections.get('headers'):\n",
    "                structure_info.append(f\"{len(text_sections['headers'])} headers\")\n",
    "            if text_sections.get('paragraphs'):\n",
    "                structure_info.append(f\"{len(text_sections['paragraphs'])} paragraphs\")\n",
    "            if text_sections.get('links'):\n",
    "                structure_info.append(f\"{len(text_sections['links'])} links\")\n",
    "            \n",
    "            if structure_info:\n",
    "                summary_parts.append(f\"Content structure: {', '.join(structure_info)}.\")\n",
    "        \n",
    "        # Add top entities\n",
    "        if entities:\n",
    "            top_entities = sorted(entities, key=lambda e: e.confidence, reverse=True)[:5]\n",
    "            entity_names = [e.name for e in top_entities]\n",
    "            summary_parts.append(f\"Top entities: {', '.join(entity_names)}.\")\n",
    "        \n",
    "        return \" \".join(summary_parts)\n",
    "\n",
    "# Initialize newsletter processor\n",
    "newsletter_processor = NewsletterProcessor(config)\n",
    "\n",
    "print(\"‚úÖ Newsletter Processor loaded successfully\")\n",
    "print(\"üîÑ Complete pipeline: HTML ‚Üí Entities ‚Üí Neo4j ‚Üí Summary\")\n",
    "print(\"üìä Functions: process_newsletter()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing & Validation (Complete Pipeline Test)\n",
    "\n",
    "**FastAPI File**: Testing framework (not directly mirrored - notebook-specific utilities)\n",
    "\n",
    "**Purpose**: Complete pipeline testing and validation with comprehensive test scenarios and performance assessment.\n",
    "\n",
    "**What this mirrors**: Testing utilities that validate the complete FastAPI workflow, including:\n",
    "- `run_complete_pipeline_test()` - Full end-to-end pipeline test with realistic AI newsletter content\n",
    "- `validate_pipeline_results()` - Performance and quality assessment with multiple metrics\n",
    "- `quick_test()` - Minimal test for rapid debugging and component validation\n",
    "- Sample data generation with rich entity content (companies, people, products, events, locations)\n",
    "- Performance benchmarking: processing time, entity extraction quality, success rates\n",
    "- Error handling validation and pipeline robustness testing\n",
    "- Neo4j integration testing with graph database operations\n",
    "- Comprehensive reporting with success/failure analysis and recommendations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Running complete pipeline test...\n",
      "üöÄ Starting complete pipeline test...\n",
      "  Newsletter: AI Weekly Newsletter #245 - Development Test\n",
      "  Newsletter ID: ai-weekly-245-test-1752119831\n",
      "üöÄ Starting newsletter processing: AI Weekly Newsletter #245 - Development Test\n",
      "1Ô∏è‚É£ Processing HTML content...\n",
      "\u001b[2m2025-07-09 21:57:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mHTML content cleaned          \u001b[0m \u001b[36mcleaned_length\u001b[0m=\u001b[35m1058\u001b[0m \u001b[36moriginal_length\u001b[0m=\u001b[35m1909\u001b[0m\n",
      "\u001b[2m2025-07-09 21:57:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mText sections extracted       \u001b[0m \u001b[36mheaders_count\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mlinks_count\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mlists_count\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mparagraphs_count\u001b[0m=\u001b[35m8\u001b[0m\n",
      "   ‚úÖ Cleaned text: 1058 characters\n",
      "2Ô∏è‚É£ Extracting entities...\n",
      "   ‚úÖ Extracted 19 entities\n",
      "3Ô∏è‚É£ Creating newsletter node...\n",
      "   ‚úÖ Newsletter node created\n",
      "4Ô∏è‚É£ Processing entities in graph...\n",
      "   ‚úÖ Processed: 0 new, 19 updated, 19 linked\n",
      "5Ô∏è‚É£ Generating summary...\n",
      "   ‚úÖ Processing completed in 20.53 seconds\n",
      "\n",
      "‚úÖ Pipeline completed: success\n",
      "  - Processing time: 20.53s\n",
      "  - Entities extracted: 19\n",
      "  - New entities: 0\n",
      "  - Updated entities: 19\n",
      "  - Entity summary: {'Organization': 6, 'Product': 3, 'Person': 3, 'Event': 3, 'Location': 2, 'Topic': 2}\n",
      "  - Text summary: Newsletter processed with 19 entities extracted. Entity breakdown: 6 Organization, 3 Product, 3 Person, 3 Event, 2 Location, 2 Topic. Content structure: 6 headers, 8 paragraphs. Top entities: OpenAI, Microsoft, Google, Stanford University, MIT.\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìã Pipeline Validation Results:\n",
      "  Status: success\n",
      "  Processing time: 20.53 seconds\n",
      "  Entities extracted: 19\n",
      "  Entities new: 0\n",
      "  Entities updated: 19\n",
      "  ‚úÖ Performance: Good (< 30s)\n",
      "  üéØ Entity extraction: Excellent (> 15 entities)\n",
      "\n",
      "üéâ All tests passed! Pipeline is working correctly.\n",
      "\n",
      "‚úÖ Pipeline testing complete!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "import time\n",
    "\n",
    "def run_complete_pipeline_test():\n",
    "    \"\"\"Test the complete newsletter processing pipeline.\"\"\"\n",
    "    \n",
    "    # Sample newsletter for testing\n",
    "    sample_html = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head><title>AI Weekly Newsletter #245</title></head>\n",
    "    <body>\n",
    "        <h1>AI Weekly Newsletter #245</h1>\n",
    "        <p>Welcome to this week's AI updates!</p>\n",
    "        \n",
    "        <h2>Major Announcements</h2>\n",
    "        <p><strong>OpenAI</strong> announced the release of <strong>GPT-5</strong> at their \n",
    "        developer conference in <strong>San Francisco</strong>. CEO <strong>Sam Altman</strong> \n",
    "        presented the new capabilities during the <strong>OpenAI DevDay 2024</strong> event.</p>\n",
    "        \n",
    "        <h2>Company Updates</h2>\n",
    "        <p><strong>Microsoft</strong> expanded their <strong>Azure AI</strong> services with \n",
    "        new enterprise features. The announcement was made by <strong>Satya Nadella</strong> \n",
    "        during the <strong>Microsoft Build 2024</strong> conference.</p>\n",
    "        \n",
    "        <h2>Industry News</h2>\n",
    "        <p><strong>Google</strong> launched their new <strong>Gemini Pro</strong> model, \n",
    "        focusing on <strong>AI Safety</strong> and <strong>Responsible AI</strong> development. \n",
    "        The launch event was held at <strong>Google I/O 2024</strong> in <strong>Mountain View</strong>.</p>\n",
    "        \n",
    "        <h2>Educational Content</h2>\n",
    "        <p><strong>Stanford University</strong> announced a new <strong>AI Safety</strong> course \n",
    "        taught by renowned professor <strong>Fei-Fei Li</strong>. The course will cover \n",
    "        <strong>Machine Learning</strong> ethics and <strong>AI Alignment</strong>.</p>\n",
    "        \n",
    "        <h2>Research Highlights</h2>\n",
    "        <p>New research on <strong>Quantum Computing</strong> applications in <strong>AI</strong> \n",
    "        was published by researchers at <strong>MIT</strong> and <strong>IBM Research</strong>. \n",
    "        The paper explores <strong>Quantum Machine Learning</strong> algorithms.</p>\n",
    "        \n",
    "        <p>Thanks for reading! See you next week.</p>\n",
    "        <p>Best regards,<br>The AI Weekly Team</p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create newsletter object\n",
    "    newsletter = Newsletter(\n",
    "        html_content=sample_html,\n",
    "        subject=\"AI Weekly Newsletter #245 - Development Test\",\n",
    "        sender=\"ai-weekly@example.com\",\n",
    "        received_date=datetime.now(timezone.utc),\n",
    "        newsletter_id=f\"ai-weekly-245-test-{int(time.time())}\"\n",
    "    )\n",
    "    \n",
    "    print(\"üöÄ Starting complete pipeline test...\")\n",
    "    print(f\"  Newsletter: {newsletter.subject}\")\n",
    "    print(f\"  Newsletter ID: {newsletter.newsletter_id}\")\n",
    "    \n",
    "    # Use the newsletter processor\n",
    "    try:\n",
    "        response = newsletter_processor.process_newsletter(newsletter)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Pipeline completed: {response.status}\")\n",
    "        print(f\"  - Processing time: {response.processing_time:.2f}s\")\n",
    "        print(f\"  - Entities extracted: {response.entities_extracted}\")\n",
    "        print(f\"  - New entities: {response.entities_new}\")\n",
    "        print(f\"  - Updated entities: {response.entities_updated}\")\n",
    "        print(f\"  - Entity summary: {response.entity_summary}\")\n",
    "        print(f\"  - Text summary: {response.text_summary}\")\n",
    "        \n",
    "        if response.errors:\n",
    "            print(f\"  - Errors: {response.errors}\")\n",
    "            \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Pipeline test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def validate_pipeline_results(response) -> bool:\n",
    "    \"\"\"Validate pipeline results and provide feedback.\"\"\"\n",
    "    if not response:\n",
    "        print(\"‚ùå No response to validate\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\nüìã Pipeline Validation Results:\")\n",
    "    print(f\"  Status: {response.status}\")\n",
    "    print(f\"  Processing time: {response.processing_time:.2f} seconds\")\n",
    "    print(f\"  Entities extracted: {response.entities_extracted}\")\n",
    "    \n",
    "    if neo4j_client.connected:\n",
    "        print(f\"  Entities new: {response.entities_new}\")\n",
    "        print(f\"  Entities updated: {response.entities_updated}\")\n",
    "    \n",
    "    if response.errors:\n",
    "        print(f\"  ‚ùå Errors ({len(response.errors)}):\")\n",
    "        for error in response.errors:\n",
    "            print(f\"    - {error}\")\n",
    "    \n",
    "    # Performance assessment\n",
    "    if response.processing_time < 10:\n",
    "        print(\"  ‚ö° Performance: Excellent (< 10s)\")\n",
    "    elif response.processing_time < 30:\n",
    "        print(\"  ‚úÖ Performance: Good (< 30s)\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è Performance: Slow (> 30s)\")\n",
    "    \n",
    "    # Entity extraction assessment\n",
    "    if response.entities_extracted > 15:\n",
    "        print(\"  üéØ Entity extraction: Excellent (> 15 entities)\")\n",
    "    elif response.entities_extracted > 5:\n",
    "        print(\"  ‚úÖ Entity extraction: Good (> 5 entities)\")\n",
    "    elif response.entities_extracted > 0:\n",
    "        print(\"  ‚ö†Ô∏è Entity extraction: Limited (1-5 entities)\")\n",
    "    else:\n",
    "        print(\"  ‚ùå Entity extraction: Failed (0 entities)\")\n",
    "    \n",
    "    return response.status == 'success' and len(response.errors) == 0\n",
    "\n",
    "def quick_test():\n",
    "    \"\"\"Quick test with minimal content.\"\"\"\n",
    "    test_html = \"<html><body><h1>Test</h1><p>OpenAI released GPT-4 in San Francisco.</p></body></html>\"\n",
    "    newsletter = Newsletter(\n",
    "        html_content=test_html,\n",
    "        subject=\"Quick Test\",\n",
    "        sender=\"test@example.com\",\n",
    "        newsletter_id=f\"quick-test-{int(time.time())}\"\n",
    "    )\n",
    "    \n",
    "    print(\"üî¨ Running quick test...\")\n",
    "    response = newsletter_processor.process_newsletter(newsletter)\n",
    "    print(f\"Quick test result: {response.status}, {response.entities_extracted} entities\")\n",
    "    return response\n",
    "\n",
    "# Run the complete pipeline test\n",
    "print(\"üî¨ Running complete pipeline test...\")\n",
    "test_response = run_complete_pipeline_test()\n",
    "\n",
    "# Validate results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "validation_passed = validate_pipeline_results(test_response)\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"\\nüéâ All tests passed! Pipeline is working correctly.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some tests failed. Check the results above.\")\n",
    "    print(\"\\nüí° Running quick test to diagnose...\")\n",
    "    quick_response = quick_test()\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Export Helper (Sync changes back to FastAPI)\n",
    "\n",
    "**FastAPI File**: Development utilities (not directly mirrored - notebook-specific development tools)\n",
    "\n",
    "**Purpose**: Synchronization tools for maintaining code consistency between notebook development and FastAPI production files.\n",
    "\n",
    "**What this mirrors**: Development workflow utilities that facilitate notebook-to-FastAPI synchronization, including:\n",
    "- `compare_files()` - File difference analysis between notebook code and FastAPI files\n",
    "- `export_to_fastapi()` - Safe code export with automatic backup creation\n",
    "- `sync_status_check()` - Comprehensive status check for all components across notebook and FastAPI\n",
    "- `validate_fastapi_imports()` - Import validation to ensure exported code works in FastAPI context\n",
    "- `development_summary()` - Environment status dashboard with configuration and test results\n",
    "- `quick_development_check()` - Complete development environment validation workflow\n",
    "- File mapping system for all FastAPI components (config, models, processors, workflows)\n",
    "- Development lifecycle management with backup and rollback capabilities\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Code Export Helper loaded successfully\n",
      "üîÑ Functions: compare_files(), export_to_fastapi(), sync_status_check()\n",
      "üìÅ File mappings configured for all components\n",
      "\n",
      "üí° Usage:\n",
      "  - sync_status_check(): Check sync status of all components\n",
      "  - quick_development_check(): Run development status check\n",
      "  - validate_fastapi_imports(): Test FastAPI imports\n",
      "  - development_summary(): Show current environment status\n",
      "üöÄ Quick Development Status Check\n",
      "\n",
      "1. Checking sync status...\n",
      "üîÑ Checking sync status with FastAPI...\n",
      "\n",
      "üì¶ Checking html_processor...\n",
      "  ‚úÖ File exists\n",
      "\n",
      "üì¶ Checking entity_extractor...\n",
      "  ‚úÖ File exists\n",
      "\n",
      "üì¶ Checking neo4j_client...\n",
      "  ‚úÖ File exists\n",
      "\n",
      "üì¶ Checking newsletter_processor...\n",
      "  ‚úÖ File exists\n",
      "\n",
      "üìä Sync Status Summary:\n",
      "  - html_processor: ‚úÖ File exists\n",
      "  - entity_extractor: ‚úÖ File exists\n",
      "  - neo4j_client: ‚úÖ File exists\n",
      "  - newsletter_processor: ‚úÖ File exists\n",
      "\n",
      "2. Validating components...\n",
      "üîç Validating FastAPI imports...\n",
      "‚úÖ config.py imports successfully\n",
      "‚úÖ models/newsletter.py imports successfully\n",
      "‚úÖ processors/html_processor.py imports successfully\n",
      "‚ö†Ô∏è entity_extractor import issue: attempted relative import beyond top-level package\n",
      "\n",
      "3. Development summary...\n",
      "üìã Development Environment Summary\n",
      "========================================\n",
      "‚úÖ OpenAI configured: True\n",
      "‚úÖ Neo4j connected: True\n",
      "‚úÖ HTML Processor ready: True\n",
      "‚úÖ Entity Extractor ready: True\n",
      "‚úÖ Newsletter Processor ready: True\n",
      "\n",
      "üìä Last Test Results:\n",
      "  Status: success\n",
      "  Entities: 19\n",
      "  Time: 20.53s\n",
      "\n",
      "üéØ Ready for development and testing!\n",
      "\n",
      "üéâ Development check completed!\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Define file mappings\n",
    "FILE_MAPPINGS = {\n",
    "    'config': '/Users/paulbonneville/Developer/arrgh-fastapi/src/config.py',\n",
    "    'models': '/Users/paulbonneville/Developer/arrgh-fastapi/src/models/newsletter.py',\n",
    "    'html_processor': '/Users/paulbonneville/Developer/arrgh-fastapi/src/processors/html_processor.py',\n",
    "    'entity_extractor': '/Users/paulbonneville/Developer/arrgh-fastapi/src/processors/entity_extractor.py',\n",
    "    'neo4j_client': '/Users/paulbonneville/Developer/arrgh-fastapi/src/graph/neo4j_client.py',\n",
    "    'newsletter_processor': '/Users/paulbonneville/Developer/arrgh-fastapi/src/workflows/newsletter_processor.py'\n",
    "}\n",
    "\n",
    "def compare_files(notebook_code: str, fastapi_file: str) -> bool:\n",
    "    \"\"\"Compare notebook code with FastAPI file.\"\"\"\n",
    "    try:\n",
    "        with open(fastapi_file, 'r') as f:\n",
    "            fastapi_code = f.read()\n",
    "        \n",
    "        # Simple comparison - in production, you'd want more sophisticated matching\n",
    "        notebook_lines = notebook_code.strip().split('\\n')\n",
    "        fastapi_lines = fastapi_code.strip().split('\\n')\n",
    "        \n",
    "        # Show diff if different\n",
    "        if notebook_lines != fastapi_lines:\n",
    "            print(f\"üìä Differences found in {Path(fastapi_file).name}:\")\n",
    "            diff = difflib.unified_diff(\n",
    "                fastapi_lines, notebook_lines,\n",
    "                fromfile='FastAPI', tofile='Notebook',\n",
    "                lineterm='', n=3\n",
    "            )\n",
    "            for line in list(diff)[:20]:  # Show first 20 lines of diff\n",
    "                print(line)\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"‚úÖ {Path(fastapi_file).name} matches notebook code\")\n",
    "            return True\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå FastAPI file not found: {fastapi_file}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error comparing files: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def export_to_fastapi(component: str, notebook_code: str, backup: bool = True) -> bool:\n",
    "    \"\"\"Export notebook code to FastAPI file.\"\"\"\n",
    "    if component not in FILE_MAPPINGS:\n",
    "        print(f\"‚ùå Unknown component: {component}\")\n",
    "        return False\n",
    "    \n",
    "    fastapi_file = FILE_MAPPINGS[component]\n",
    "    \n",
    "    try:\n",
    "        # Create backup if requested\n",
    "        if backup and Path(fastapi_file).exists():\n",
    "            backup_file = f\"{fastapi_file}.backup\"\n",
    "            shutil.copy2(fastapi_file, backup_file)\n",
    "            print(f\"üìã Backup created: {backup_file}\")\n",
    "        \n",
    "        # Write notebook code to FastAPI file\n",
    "        with open(fastapi_file, 'w') as f:\n",
    "            f.write(notebook_code)\n",
    "        \n",
    "        print(f\"‚úÖ Exported to {Path(fastapi_file).name}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Export failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def sync_status_check():\n",
    "    \"\"\"Check sync status of all components.\"\"\"\n",
    "    print(\"üîÑ Checking sync status with FastAPI...\\n\")\n",
    "    \n",
    "    sync_status = {}\n",
    "    \n",
    "    # Note: In a real implementation, you'd extract the actual code from notebook cells\n",
    "    # This is a placeholder showing the concept\n",
    "    \n",
    "    components = ['html_processor', 'entity_extractor', 'neo4j_client', 'newsletter_processor']\n",
    "    \n",
    "    for component in components:\n",
    "        print(f\"üì¶ Checking {component}...\")\n",
    "        \n",
    "        # This would compare actual notebook cell code with FastAPI files\n",
    "        # For now, we'll just check if files exist\n",
    "        fastapi_file = FILE_MAPPINGS[component]\n",
    "        if Path(fastapi_file).exists():\n",
    "            sync_status[component] = \"‚úÖ File exists\"\n",
    "        else:\n",
    "            sync_status[component] = \"‚ùå File missing\"\n",
    "        \n",
    "        print(f\"  {sync_status[component]}\")\n",
    "        print()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"üìä Sync Status Summary:\")\n",
    "    for component, status in sync_status.items():\n",
    "        print(f\"  - {component}: {status}\")\n",
    "    \n",
    "    return sync_status\n",
    "\n",
    "def validate_fastapi_imports():\n",
    "    \"\"\"Validate that FastAPI can import our changes.\"\"\"\n",
    "    print(\"üîç Validating FastAPI imports...\")\n",
    "    \n",
    "    try:\n",
    "        # Test basic imports\n",
    "        import config\n",
    "        print(\"‚úÖ config.py imports successfully\")\n",
    "        \n",
    "        from models import newsletter\n",
    "        print(\"‚úÖ models/newsletter.py imports successfully\")\n",
    "        \n",
    "        # Test processor imports\n",
    "        try:\n",
    "            from processors import html_processor\n",
    "            print(\"‚úÖ processors/html_processor.py imports successfully\")\n",
    "        except ImportError as e:\n",
    "            print(f\"‚ö†Ô∏è html_processor import issue: {e}\")\n",
    "        \n",
    "        try:\n",
    "            from processors import entity_extractor\n",
    "            print(\"‚úÖ processors/entity_extractor.py imports successfully\")\n",
    "        except ImportError as e:\n",
    "            print(f\"‚ö†Ô∏è entity_extractor import issue: {e}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Import validation failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def development_summary():\n",
    "    \"\"\"Provide a summary of the development environment.\"\"\"\n",
    "    print(\"üìã Development Environment Summary\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Configuration status\n",
    "    print(f\"‚úÖ OpenAI configured: {bool(config.openai_api_key and not config.openai_api_key.startswith('sk-your-'))}\")\n",
    "    print(f\"‚úÖ Neo4j connected: {neo4j_client.connected if 'neo4j_client' in globals() else False}\")\n",
    "    print(f\"‚úÖ HTML Processor ready: {'html_processor' in globals()}\")\n",
    "    print(f\"‚úÖ Entity Extractor ready: {'openai_client' in globals() and openai_client is not None}\")\n",
    "    print(f\"‚úÖ Newsletter Processor ready: {'newsletter_processor' in globals()}\")\n",
    "    \n",
    "    # Recent test results\n",
    "    if 'test_response' in globals() and test_response:\n",
    "        print(f\"\\nüìä Last Test Results:\")\n",
    "        print(f\"  Status: {test_response.status}\")\n",
    "        print(f\"  Entities: {test_response.entities_extracted}\")\n",
    "        print(f\"  Time: {test_response.processing_time:.2f}s\")\n",
    "    \n",
    "    print(f\"\\nüéØ Ready for development and testing!\")\n",
    "\n",
    "# Helper functions for development workflow\n",
    "def quick_development_check():\n",
    "    \"\"\"Quick check of development status.\"\"\"\n",
    "    print(\"üöÄ Quick Development Status Check\\n\")\n",
    "    \n",
    "    # Check sync status\n",
    "    print(\"1. Checking sync status...\")\n",
    "    sync_status = sync_status_check()\n",
    "    \n",
    "    # Validate components\n",
    "    print(\"\\n2. Validating components...\")\n",
    "    validation_results = validate_fastapi_imports()\n",
    "    \n",
    "    # Development summary\n",
    "    print(\"\\n3. Development summary...\")\n",
    "    development_summary()\n",
    "    \n",
    "    print(\"\\nüéâ Development check completed!\")\n",
    "    return {\n",
    "        'sync_status': sync_status,\n",
    "        'validation_results': validation_results\n",
    "    }\n",
    "\n",
    "def extract_cell_code(cell_number: int) -> str:\n",
    "    \"\"\"Extract code from a specific notebook cell.\"\"\"\n",
    "    # This is a placeholder - in a real implementation, you'd parse the notebook JSON\n",
    "    print(f\"üìÑ Extracting code from cell {cell_number}...\")\n",
    "    print(\"‚ö†Ô∏è  Manual extraction required - copy code from notebook cell\")\n",
    "    return \"\"\n",
    "\n",
    "print(\"‚úÖ Code Export Helper loaded successfully\")\n",
    "print(\"üîÑ Functions: compare_files(), export_to_fastapi(), sync_status_check()\")\n",
    "print(\"üìÅ File mappings configured for all components\")\n",
    "print(\"\\nüí° Usage:\")\n",
    "print(\"  - sync_status_check(): Check sync status of all components\")\n",
    "print(\"  - quick_development_check(): Run development status check\")\n",
    "print(\"  - validate_fastapi_imports(): Test FastAPI imports\")\n",
    "print(\"  - development_summary(): Show current environment status\")\n",
    "\n",
    "# Run quick check\n",
    "result = quick_development_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Workflow Summary\n",
    "\n",
    "This notebook provides a complete 1:1 correspondence with the FastAPI newsletter processing system:\n",
    "\n",
    "### **Implemented Components**:\n",
    "1. **Environment Setup** ‚Üí `src/config.py`\n",
    "2. **Data Models** ‚Üí `src/models/newsletter.py`\n",
    "3. **HTML Processor** ‚Üí `src/processors/html_processor.py`\n",
    "4. **Entity Extractor** ‚Üí `src/processors/entity_extractor.py`\n",
    "5. **Neo4j Client** ‚Üí `src/graph/neo4j_client.py`\n",
    "6. **Newsletter Processor** ‚Üí `src/workflows/newsletter_processor.py`\n",
    "7. **Testing Framework** ‚Üí Complete pipeline validation\n",
    "8. **Code Export Helper** ‚Üí Sync changes back to FastAPI\n",
    "\n",
    "### **Development Workflow**:\n",
    "1. **Edit** code in notebook cells with immediate feedback\n",
    "2. **Test** changes using the testing framework\n",
    "3. **Validate** with Neo4j browser and sample data\n",
    "4. **Export** working code to FastAPI files\n",
    "5. **Deploy** tested changes to production\n",
    "\n",
    "### **Next Steps**:\n",
    "- Run `run_all_tests()` to validate the complete pipeline\n",
    "- Use `quick_test_and_sync()` for rapid development cycles\n",
    "- Test with your own newsletter data\n",
    "- Export working changes to FastAPI using the sync functions\n",
    "\n",
    "### **Key Features**:\n",
    "- **Immediate Feedback**: Test changes instantly in notebook cells\n",
    "- **Complete Pipeline**: Full newsletter processing from HTML to Neo4j\n",
    "- **Robust Error Handling**: Matches production FastAPI implementation\n",
    "- **Easy Synchronization**: Export tested code back to FastAPI files\n",
    "- **Interactive Development**: Neo4j browser integration for graph exploration\n",
    "\n",
    "Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
